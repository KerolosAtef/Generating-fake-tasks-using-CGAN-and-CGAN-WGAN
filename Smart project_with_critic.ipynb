{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import important dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8427_tP1JEW",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "%matplotlib inline\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download MCS dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# !gdown --id 11_0c5fvFpydBb0-pWCDcxzp3-ZiUtKGX"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "         ID   Latitude  Longitude  Day  Hour  Minute  Duration  RemainingTime  \\\n0         1  45.442142 -75.303369    1     4      13        40             40   \n1         1  45.442154 -75.304366    1     4      23        40             30   \n2         1  45.442104 -75.303963    1     4      33        40             20   \n3         1  45.441868 -75.303577    1     4      43        40             10   \n4         2  45.447727 -75.147722    2    15      49        30             30   \n...     ...        ...        ...  ...   ...     ...       ...            ...   \n14479  3999  45.445303 -75.165596    2     1      18        20             20   \n14480  3999  45.445574 -75.165168    2     1      28        20             10   \n14481  4000  45.436682 -75.152416    0    12      21        30             30   \n14482  4000  45.436978 -75.153278    0    12      31        30             20   \n14483  4000  45.436983 -75.153240    0    12      41        30             10   \n\n       Resources  Coverage  OnPeakHours  GridNumber  Ligitimacy  \n0              9        91            0      131380           1  \n1              9        91            0      131380           1  \n2              9        91            0      121996           1  \n3              9        91            0      121996           1  \n4              5        47            0      140784           1  \n...          ...       ...          ...         ...         ...  \n14479         10        80            0      131397           1  \n14480         10        80            0      131397           1  \n14481          4        63            0      122015           1  \n14482          4        63            0      122015           1  \n14483          4        63            0      122015           1  \n\n[14484 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n      <th>Ligitimacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>45.442142</td>\n      <td>-75.303369</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>40</td>\n      <td>40</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>45.442154</td>\n      <td>-75.304366</td>\n      <td>1</td>\n      <td>4</td>\n      <td>23</td>\n      <td>40</td>\n      <td>30</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>45.442104</td>\n      <td>-75.303963</td>\n      <td>1</td>\n      <td>4</td>\n      <td>33</td>\n      <td>40</td>\n      <td>20</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>45.441868</td>\n      <td>-75.303577</td>\n      <td>1</td>\n      <td>4</td>\n      <td>43</td>\n      <td>40</td>\n      <td>10</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>45.447727</td>\n      <td>-75.147722</td>\n      <td>2</td>\n      <td>15</td>\n      <td>49</td>\n      <td>30</td>\n      <td>30</td>\n      <td>5</td>\n      <td>47</td>\n      <td>0</td>\n      <td>140784</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14479</th>\n      <td>3999</td>\n      <td>45.445303</td>\n      <td>-75.165596</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18</td>\n      <td>20</td>\n      <td>20</td>\n      <td>10</td>\n      <td>80</td>\n      <td>0</td>\n      <td>131397</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14480</th>\n      <td>3999</td>\n      <td>45.445574</td>\n      <td>-75.165168</td>\n      <td>2</td>\n      <td>1</td>\n      <td>28</td>\n      <td>20</td>\n      <td>10</td>\n      <td>10</td>\n      <td>80</td>\n      <td>0</td>\n      <td>131397</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14481</th>\n      <td>4000</td>\n      <td>45.436682</td>\n      <td>-75.152416</td>\n      <td>0</td>\n      <td>12</td>\n      <td>21</td>\n      <td>30</td>\n      <td>30</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14482</th>\n      <td>4000</td>\n      <td>45.436978</td>\n      <td>-75.153278</td>\n      <td>0</td>\n      <td>12</td>\n      <td>31</td>\n      <td>30</td>\n      <td>20</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14483</th>\n      <td>4000</td>\n      <td>45.436983</td>\n      <td>-75.153240</td>\n      <td>0</td>\n      <td>12</td>\n      <td>41</td>\n      <td>30</td>\n      <td>10</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>14484 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MCSDatasetNEXTCONLab.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset into training dataset (80%) and test dataset (20%)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(2897, 12)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Ligitimacy']\n",
    "X = df.drop(['Ligitimacy'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=seed, stratify=y)\n",
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement classic classifiers (Adaboost and RF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "adaBoostClassifier = AdaBoostClassifier()\n",
    "randomForestClassifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Adaboost and RF via training dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Traing Accuracy: 0.9513247605074653\n",
      "Random Forest Traing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "## fit models on training data\n",
    "adaBoostClassifier.fit(X_train,y_train)\n",
    "randomForestClassifier.fit(X_train,y_train)\n",
    "\n",
    "y_adaBoost = adaBoostClassifier.predict(X_train)\n",
    "y_randomForest = randomForestClassifier.predict(X_train)\n",
    "AdaBoost_Training_Accuracy= accuracy_score(y_adaBoost, y_train)\n",
    "Random_Forest_Traing_Accuracy= accuracy_score(y_randomForest , y_train)\n",
    "\n",
    "print('AdaBoost Traing Accuracy:', AdaBoost_Training_Accuracy)\n",
    "print('Random Forest Traing Accuracy:', Random_Forest_Traing_Accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verify detection performance using test dataset and present results comparison in bar chart\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Testing Accuracy: 0.9423541594753193\n",
      "Random Forest Testing Accuracy: 0.9965481532619952\n"
     ]
    }
   ],
   "source": [
    "y_pred_adaBoost = adaBoostClassifier.predict(X_test)\n",
    "y_pred_randomForest = randomForestClassifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "AdaBoost_Testing_Accuracy = accuracy_score(y_pred_adaBoost, y_test)\n",
    "Random_Forest_Testing_Accuracy = accuracy_score(y_pred_randomForest, y_test)\n",
    "\n",
    "print('AdaBoost Testing Accuracy:', AdaBoost_Testing_Accuracy)\n",
    "print('Random Forest Testing Accuracy:', Random_Forest_Testing_Accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000001F4C965C130>\n",
      "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000001F4E249DC00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirolos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Kirolos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Random Forest  Confusion Matrix ')"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(plot_confusion_matrix(adaBoostClassifier, X_test, y_test))\n",
    "plt.title(\"AdaBoost Confusion Matrix \")\n",
    "print(plot_confusion_matrix(randomForestClassifier, X_test, y_test))\n",
    "plt.title(\"Random Forest  Confusion Matrix \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "{'AdaBoost_Testing_Accuracy': 0.9423541594753193,\n 'Random_Forest_Testing_Accuracy': 0.9965481532619952}"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_Testing_Accuracy = accuracy_score(y_pred_adaBoost , y_test)\n",
    "Random_Forest_Testing_Accuracy =accuracy_score(y_pred_randomForest , y_test)\n",
    "acc_dict = {'AdaBoost_Testing_Accuracy':AdaBoost_Testing_Accuracy,\n",
    "            'Random_Forest_Testing_Accuracy':Random_Forest_Testing_Accuracy}\n",
    "acc_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_acc_tup = sorted(acc_dict.items(),key=lambda item:item[1])\n",
    "acc_dict = {k:v for k,v in sorted_acc_tup}\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "sns.barplot(x = list(acc_dict.keys()), y=list(acc_dict.values()))\n",
    "plt.grid()\n",
    "plt.ylabel('Scores');\n",
    "plt.title('AdaBoost VS Random_Forest Accuracies');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement Conditional GAN with Wasserstein loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For good generation we should make the dataset balanced, so our generator can recognise the features of ligitimat tasks and unligitimat tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=seed)\n",
    "X_train_smoted, y_train_smoted = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.99249812, 0.24691239, 0.19038729, ..., 0.8       , 0.        ,\n        0.24385902],\n       [0.50187547, 0.8656828 , 0.48180773, ..., 0.07142857, 0.        ,\n        0.85362741],\n       [0.36184046, 0.76124423, 0.83948626, ..., 0.32857143, 0.        ,\n        0.7560968 ],\n       ...,\n       [0.28982246, 0.53945756, 0.47422468, ..., 0.65714286, 0.        ,\n        0.53656001],\n       [0.75743936, 0.67476991, 0.16140315, ..., 0.67142857, 0.        ,\n        0.68287282],\n       [0.03325831, 0.68059008, 0.16064208, ..., 0.04285714, 0.        ,\n        0.68287282]])"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_smoted_scaled = scaler.fit_transform(X_train_smoted)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_smoted_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants and hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_classes = 2\n",
    "take_size = 12\n",
    "latent_dim = 126"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "task_shape = (take_size + num_classes, 1)\n",
    "X_train_smoted = X_train_smoted.astype(np.float32)\n",
    "X_train_smoted_scaled = X_train_smoted_scaled.astype(np.float32)\n",
    "all_labels = keras.utils.to_categorical(y_train_smoted, 2)\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_smoted_scaled, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "n7BqV_T41JEa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 14, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 7, 64)             256       \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 7, 64)             0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 4, 128)            24704     \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 4, 128)            0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 4, 128)            0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 2, 256)            65792     \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 2, 256)            0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 2, 256)            0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 1, 512)            393728    \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 1, 512)            0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 484,993\n",
      "Trainable params: 484,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=2,\n",
    "    strides=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5,\n",
    "):\n",
    "    x = layers.Conv1D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_discriminator_model():\n",
    "    img_input = layers.Input(shape=task_shape)\n",
    "    # Zero pad the input to make the input images size to (32, 32, 1).\n",
    "    # x = layers.ZeroPadding2D((2, 2))(img_input)\n",
    "    x = conv_block(\n",
    "        img_input,\n",
    "        64,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        use_bn=False,\n",
    "        use_bias=True,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        128,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        256,\n",
    "        kernel_size=2,\n",
    "        strides=2,\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        512,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    d_model = keras.models.Model(img_input, x, name=\"discriminator\")\n",
    "    return d_model\n",
    "\n",
    "d_model = get_discriminator_model()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaqH7X0p1JEb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "8GmdwF1Q1JEc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              524288    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               1048576   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,593,356\n",
      "Trainable params: 1,584,652\n",
      "Non-trainable params: 8,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    padding=\"same\",\n",
    "    use_bn=False,\n",
    "    use_bias=True,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3,\n",
    "):\n",
    "    # x = layers.UpSampling2D(up_size)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_generator_model():\n",
    "    noise = layers.Input(shape=(latent_dim+num_classes,))\n",
    "    x = layers.Dense(4 * 4 * 256, use_bias=False,activation='relu')(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(256, use_bias=False,activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(take_size,activation='leaky_relu')(x)\n",
    "    g_model = keras.models.Model(noise, x, name=\"generator\")\n",
    "    return g_model\n",
    "\n",
    "\n",
    "g_model = get_generator_model()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpLAmH171JEd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the WGAN-GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "wZReMVPk1JEd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size,1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_task,one_hot_labeld=data\n",
    "        if isinstance(real_task, tuple):\n",
    "            real_task = real_task[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        real_task=tf.concat([real_task,one_hot_labeld],axis=1)\n",
    "        batch_size = tf.shape(real_task)[0]\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            random_latent_vectors=tf.concat([random_latent_vectors,one_hot_labeld],axis=1)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_task = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_task=tf.concat([fake_task,one_hot_labeld],axis=1)\n",
    "                fake_logits = self.discriminator(fake_task, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_task, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_task, fake_task)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_latent_vectors=tf.concat([random_latent_vectors,one_hot_labeld],axis=1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_task = self.generator(random_latent_vectors, training=True)\n",
    "            generated_task=tf.concat([generated_task,one_hot_labeld],axis=1)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_task, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply the provided training dataset to CGAN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPw5zmmC1JEf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "Al8UuPvA1JEf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 31s 1s/step - d_loss: 1.0306 - g_loss: 0.7373\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 27s 1s/step - d_loss: -1.2707 - g_loss: 1.8086\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.2503 - g_loss: 1.7241\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.2518 - g_loss: 1.9139\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.2199 - g_loss: 2.0340\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.1819 - g_loss: 2.1434\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.1429 - g_loss: 2.1059\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.1054 - g_loss: 2.0650\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.0587 - g_loss: 1.9888\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -1.0113 - g_loss: 1.9126\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.9629 - g_loss: 1.8130\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 26s 1s/step - d_loss: -0.9146 - g_loss: 1.7624\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.8643 - g_loss: 1.6427\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.8087 - g_loss: 1.5833\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.7505 - g_loss: 1.4971\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.7024 - g_loss: 1.4171\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.6447 - g_loss: 1.3601\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 27s 1s/step - d_loss: -0.6030 - g_loss: 1.2533\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.5642 - g_loss: 1.1664\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.5148 - g_loss: 1.1729\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.4749 - g_loss: 1.1326\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 26s 1s/step - d_loss: -0.4345 - g_loss: 1.1061\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.3983 - g_loss: 1.0148\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.3610 - g_loss: 1.0102\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.3201 - g_loss: 0.9735\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 29s 1s/step - d_loss: -0.2801 - g_loss: 0.9584\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.2431 - g_loss: 0.9330\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.1997 - g_loss: 0.8448\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.1643 - g_loss: 0.7735\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.1211 - g_loss: 0.7439\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0862 - g_loss: 0.7506\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0647 - g_loss: 0.7761\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0509 - g_loss: 0.8548\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0461 - g_loss: 0.9773\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0553 - g_loss: 1.1425\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0588 - g_loss: 1.2113\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0685 - g_loss: 1.1807\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 24s 1s/step - d_loss: -0.0743 - g_loss: 1.1866\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 27s 1s/step - d_loss: -0.0706 - g_loss: 1.1461\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0787 - g_loss: 1.0984\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0859 - g_loss: 1.1291\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0838 - g_loss: 1.0354\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0842 - g_loss: 1.0884\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0885 - g_loss: 1.0652\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0899 - g_loss: 1.0060\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0935 - g_loss: 1.0576\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0918 - g_loss: 1.0617\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0961 - g_loss: 1.0974\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0991 - g_loss: 1.0206\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 25s 1s/step - d_loss: -0.0928 - g_loss: 1.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f4f371d6f0>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the optimizer for both networks\n",
    "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "epochs = 50\n",
    "\n",
    "# Get the wgan model\n",
    "wgan = WGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=latent_dim,\n",
    "    discriminator_extra_steps=3,\n",
    ")\n",
    "\n",
    "# Compile the wgan model\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "wgan.fit(dataset, batch_size=batch_size, epochs=epochs,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate synthetic fake tasks via Generator network in CGAN after the training procedure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To faul the model we will generate unligitimate(milicious) tasks and label them as 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "num_of_tasks=2000\n",
    "trained_gen = wgan.generator\n",
    "one_hot_example = keras.utils.to_categorical([0]*num_of_tasks, 2)\n",
    "# Sample noise for the interpolation.\n",
    "fake_noise = tf.random.normal(shape=(num_of_tasks, latent_dim))\n",
    "# Combine the noise and the labels and run inference with the generator.\n",
    "noise_and_labels = tf.concat([fake_noise, one_hot_example], 1)\n",
    "fake = trained_gen.predict(noise_and_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 12)"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "               ID   Latitude  Longitude       Day       Hour     Minute  \\\n0     3013.472656  45.472393 -75.203934  2.870436  10.935410  10.881277   \n1     1514.831299  45.480968 -75.232590  1.057343  13.605604  29.504301   \n2     1936.185425  45.553188 -75.244804  2.931365  11.824066  18.896584   \n3      637.891479  45.509197 -75.255020  2.953881  13.588033  10.694720   \n4     2316.576904  45.502987 -75.251091  2.329114  11.809584  15.008934   \n...           ...        ...        ...       ...        ...        ...   \n1995  1584.148438  45.456936 -75.274055  2.278354  14.567842  15.549793   \n1996  2196.732178  45.482075 -75.240044  2.317201  11.519961  19.457003   \n1997  2915.278320  45.465050 -75.220856  3.776816  11.627173  17.813435   \n1998  1483.401489  45.448112 -75.232391  1.355263  16.715073  -0.437701   \n1999  1893.715332  45.472897 -75.185936  3.383940  14.983698  17.551525   \n\n       Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n0     51.760231      42.268013   7.538090  53.774006    -0.013827   \n1     47.348515      42.168087   7.424839  59.841034     0.523665   \n2     49.883713      30.475977   7.584974  57.915310    -0.073288   \n3     44.778416      39.203648   7.375323  40.351543     1.331057   \n4     48.977791      34.718037   5.329229  59.522263    -0.009828   \n...         ...            ...        ...        ...          ...   \n1995  42.991623      23.734514   5.807235  51.328136     0.255321   \n1996  48.815395      41.061378   5.238188  57.359741     0.162162   \n1997  50.668060      37.507996   7.839029  63.592953    -0.026696   \n1998  39.935268      16.746204   2.443847  39.611137    -0.124302   \n1999  54.723583      23.030132   8.216568  52.906948     0.259485   \n\n         GridNumber  \n0     252629.093750  \n1     203812.531250  \n2     261422.421875  \n3     233566.953125  \n4     209836.125000  \n...             ...  \n1995  154048.921875  \n1996  240674.828125  \n1997  216918.046875  \n1998  203515.890625  \n1999  284486.781250  \n\n[2000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3013.472656</td>\n      <td>45.472393</td>\n      <td>-75.203934</td>\n      <td>2.870436</td>\n      <td>10.935410</td>\n      <td>10.881277</td>\n      <td>51.760231</td>\n      <td>42.268013</td>\n      <td>7.538090</td>\n      <td>53.774006</td>\n      <td>-0.013827</td>\n      <td>252629.093750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1514.831299</td>\n      <td>45.480968</td>\n      <td>-75.232590</td>\n      <td>1.057343</td>\n      <td>13.605604</td>\n      <td>29.504301</td>\n      <td>47.348515</td>\n      <td>42.168087</td>\n      <td>7.424839</td>\n      <td>59.841034</td>\n      <td>0.523665</td>\n      <td>203812.531250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1936.185425</td>\n      <td>45.553188</td>\n      <td>-75.244804</td>\n      <td>2.931365</td>\n      <td>11.824066</td>\n      <td>18.896584</td>\n      <td>49.883713</td>\n      <td>30.475977</td>\n      <td>7.584974</td>\n      <td>57.915310</td>\n      <td>-0.073288</td>\n      <td>261422.421875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>637.891479</td>\n      <td>45.509197</td>\n      <td>-75.255020</td>\n      <td>2.953881</td>\n      <td>13.588033</td>\n      <td>10.694720</td>\n      <td>44.778416</td>\n      <td>39.203648</td>\n      <td>7.375323</td>\n      <td>40.351543</td>\n      <td>1.331057</td>\n      <td>233566.953125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2316.576904</td>\n      <td>45.502987</td>\n      <td>-75.251091</td>\n      <td>2.329114</td>\n      <td>11.809584</td>\n      <td>15.008934</td>\n      <td>48.977791</td>\n      <td>34.718037</td>\n      <td>5.329229</td>\n      <td>59.522263</td>\n      <td>-0.009828</td>\n      <td>209836.125000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>1584.148438</td>\n      <td>45.456936</td>\n      <td>-75.274055</td>\n      <td>2.278354</td>\n      <td>14.567842</td>\n      <td>15.549793</td>\n      <td>42.991623</td>\n      <td>23.734514</td>\n      <td>5.807235</td>\n      <td>51.328136</td>\n      <td>0.255321</td>\n      <td>154048.921875</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>2196.732178</td>\n      <td>45.482075</td>\n      <td>-75.240044</td>\n      <td>2.317201</td>\n      <td>11.519961</td>\n      <td>19.457003</td>\n      <td>48.815395</td>\n      <td>41.061378</td>\n      <td>5.238188</td>\n      <td>57.359741</td>\n      <td>0.162162</td>\n      <td>240674.828125</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>2915.278320</td>\n      <td>45.465050</td>\n      <td>-75.220856</td>\n      <td>3.776816</td>\n      <td>11.627173</td>\n      <td>17.813435</td>\n      <td>50.668060</td>\n      <td>37.507996</td>\n      <td>7.839029</td>\n      <td>63.592953</td>\n      <td>-0.026696</td>\n      <td>216918.046875</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1483.401489</td>\n      <td>45.448112</td>\n      <td>-75.232391</td>\n      <td>1.355263</td>\n      <td>16.715073</td>\n      <td>-0.437701</td>\n      <td>39.935268</td>\n      <td>16.746204</td>\n      <td>2.443847</td>\n      <td>39.611137</td>\n      <td>-0.124302</td>\n      <td>203515.890625</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1893.715332</td>\n      <td>45.472897</td>\n      <td>-75.185936</td>\n      <td>3.383940</td>\n      <td>14.983698</td>\n      <td>17.551525</td>\n      <td>54.723583</td>\n      <td>23.030132</td>\n      <td>8.216568</td>\n      <td>52.906948</td>\n      <td>0.259485</td>\n      <td>284486.781250</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_inverse=scaler.inverse_transform(fake)\n",
    "fake_tasks_df=pd.DataFrame(fake_inverse,columns=df.columns[:-1])\n",
    "fake_tasks_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "fake_tasks_df.to_csv('Generated_fake_milicious_tasks.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the goodness of our generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "1    1760\n0     240\ndtype: int64"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = adaBoostClassifier.predict(fake_tasks_df)\n",
    "pd.DataFrame(mm).value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here the model is wrong in 1760 and right in only 240 example and this is a good evidence that we succeeded in scammimg the model because all this tasks should be calssified as unligitmate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mix the generated fake tasks with the original test dataset to obtain a new test dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mixing step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID   Latitude  Longitude       Day       Hour     Minute  \\\n3779   1031.000000  45.556369 -75.201917  3.000000  11.000000   9.000000   \n755     209.000000  45.469987 -75.155623  4.000000  16.000000   8.000000   \n13131  3653.000000  45.536579 -75.161880  5.000000   8.000000  35.000000   \n344      94.000000  45.392164 -75.235236  4.000000   4.000000  36.000000   \n4672   1283.000000  45.496407 -75.183561  4.000000   4.000000   1.000000   \n...            ...        ...        ...       ...        ...        ...   \n1995   1584.148438  45.456936 -75.274055  2.278354  14.567842  15.549793   \n1996   2196.732178  45.482075 -75.240044  2.317201  11.519961  19.457003   \n1997   2915.278320  45.465050 -75.220856  3.776816  11.627173  17.813435   \n1998   1483.401489  45.448112 -75.232391  1.355263  16.715073  -0.437701   \n1999   1893.715332  45.472897 -75.185936  3.383940  14.983698  17.551525   \n\n        Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n3779   40.000000      20.000000   1.000000  86.000000     0.000000   \n755    60.000000      10.000000   8.000000  53.000000     0.000000   \n13131  50.000000      30.000000   8.000000  63.000000     1.000000   \n344    40.000000      30.000000   6.000000  74.000000     0.000000   \n4672   50.000000      30.000000   5.000000  60.000000     0.000000   \n...          ...            ...        ...        ...          ...   \n1995   42.991623      23.734514   5.807235  51.328136     0.255321   \n1996   48.815395      41.061378   5.238188  57.359741     0.162162   \n1997   50.668060      37.507996   7.839029  63.592953    -0.026696   \n1998   39.935268      16.746204   2.443847  39.611137    -0.124302   \n1999   54.723583      23.030132   8.216568  52.906948     0.259485   \n\n          GridNumber  \n3779   319073.000000  \n755    178319.000000  \n13131  290926.000000  \n344     37549.000000  \n4672   215851.000000  \n...              ...  \n1995   154048.921875  \n1996   240674.828125  \n1997   216918.046875  \n1998   203515.890625  \n1999   284486.781250  \n\n[4897 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3779</th>\n      <td>1031.000000</td>\n      <td>45.556369</td>\n      <td>-75.201917</td>\n      <td>3.000000</td>\n      <td>11.000000</td>\n      <td>9.000000</td>\n      <td>40.000000</td>\n      <td>20.000000</td>\n      <td>1.000000</td>\n      <td>86.000000</td>\n      <td>0.000000</td>\n      <td>319073.000000</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>209.000000</td>\n      <td>45.469987</td>\n      <td>-75.155623</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n      <td>8.000000</td>\n      <td>60.000000</td>\n      <td>10.000000</td>\n      <td>8.000000</td>\n      <td>53.000000</td>\n      <td>0.000000</td>\n      <td>178319.000000</td>\n    </tr>\n    <tr>\n      <th>13131</th>\n      <td>3653.000000</td>\n      <td>45.536579</td>\n      <td>-75.161880</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>35.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>8.000000</td>\n      <td>63.000000</td>\n      <td>1.000000</td>\n      <td>290926.000000</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>94.000000</td>\n      <td>45.392164</td>\n      <td>-75.235236</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>36.000000</td>\n      <td>40.000000</td>\n      <td>30.000000</td>\n      <td>6.000000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>37549.000000</td>\n    </tr>\n    <tr>\n      <th>4672</th>\n      <td>1283.000000</td>\n      <td>45.496407</td>\n      <td>-75.183561</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>5.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>215851.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>1584.148438</td>\n      <td>45.456936</td>\n      <td>-75.274055</td>\n      <td>2.278354</td>\n      <td>14.567842</td>\n      <td>15.549793</td>\n      <td>42.991623</td>\n      <td>23.734514</td>\n      <td>5.807235</td>\n      <td>51.328136</td>\n      <td>0.255321</td>\n      <td>154048.921875</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>2196.732178</td>\n      <td>45.482075</td>\n      <td>-75.240044</td>\n      <td>2.317201</td>\n      <td>11.519961</td>\n      <td>19.457003</td>\n      <td>48.815395</td>\n      <td>41.061378</td>\n      <td>5.238188</td>\n      <td>57.359741</td>\n      <td>0.162162</td>\n      <td>240674.828125</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>2915.278320</td>\n      <td>45.465050</td>\n      <td>-75.220856</td>\n      <td>3.776816</td>\n      <td>11.627173</td>\n      <td>17.813435</td>\n      <td>50.668060</td>\n      <td>37.507996</td>\n      <td>7.839029</td>\n      <td>63.592953</td>\n      <td>-0.026696</td>\n      <td>216918.046875</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1483.401489</td>\n      <td>45.448112</td>\n      <td>-75.232391</td>\n      <td>1.355263</td>\n      <td>16.715073</td>\n      <td>-0.437701</td>\n      <td>39.935268</td>\n      <td>16.746204</td>\n      <td>2.443847</td>\n      <td>39.611137</td>\n      <td>-0.124302</td>\n      <td>203515.890625</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1893.715332</td>\n      <td>45.472897</td>\n      <td>-75.185936</td>\n      <td>3.383940</td>\n      <td>14.983698</td>\n      <td>17.551525</td>\n      <td>54.723583</td>\n      <td>23.030132</td>\n      <td>8.216568</td>\n      <td>52.906948</td>\n      <td>0.259485</td>\n      <td>284486.781250</td>\n    </tr>\n  </tbody>\n</table>\n<p>4897 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_test_dataset=pd.concat([X_test,fake_tasks_df])\n",
    "mixed_test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We should label all these tasks as unligitimate tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "3779     1\n755      0\n13131    0\n344      1\n4672     1\n        ..\n1995     0\n1996     0\n1997     0\n1998     0\n1999     0\nName: Ligitimacy, Length: 4897, dtype: int64"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_fake_tasks=pd.DataFrame({'Ligitimacy':[0]*2000},)\n",
    "# y_for_fake_tasks\n",
    "mixed_y_test=pd.concat([y_test,y_for_fake_tasks['Ligitimacy']])\n",
    "mixed_y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obtain Adaboost and RF detection performance using the new test dataset and present results in bar chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier accuracy for the mixed data= 0.6064937716969573\n",
      "RandomForestClassifier accuracy for the mixed data = 0.5934245456401879\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAI+CAYAAACc3l9RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX00lEQVR4nO3df7Dld13f8dfuJmRJ3bgIqygjBWx9FwuJDLEkMR0ECb8qJbX+wa+hxAmQAm01UzFUhwJF7UyazlA7kaG0UnQoptqUSEtabUTohi0WHIxC3riAlGmrEmATMGZJ7m7/OGftnZjNvfvOvbtnk8djJrP3ez6f+z2fTXK+87zf77nfs+Po0aMBAODE7DzVCwAAOB2JKACAAREFADAgogAABkQUAMCAiAIAGDjjZD/hkSNHjq6tua0CALD6zjxz121J9t3X2EmPqLW1ozl06M6T/bQAACds3749nz/emMt5AAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGDjjVC9gu33DObvz8LPOPNXLgIecPz18d752x12nehkA2+ZBH1EPP+vMPPXH3n2qlwEPOR+7+uX5WkQU8OC1YURV1c4k1yY5L8nhJJd398F1489L8o+T7EjysSSv7e6j27NcAIDVsJn3RF2aZHd3X5jkqiTXHBuoqj1Jrk7yA939tCR/kORRW79MAIDVspmIujjJjUnS3QeSnL9u7KIktyS5pqo+nOSPuvuLW75KAIAVs5mIOifJ7eu216rq2GXARyV5RpIfT/K8JD9SVd+5tUsEAFg9m3lj+R1J9qzb3tnd9yy//lKS3+ruP0ySqvpQku9O8unj7WzXrh3Zu/fs2WqB04rXOvBgtpmI2p/kBUmuq6oLsrh8d8zHkzypqh6V5FCSC5L8q/vb2dra0Rw6dOdstQP79u3ZeBKwLU7max1gO9xfR2wmoq5PcklV3ZzFb+BdVlVXJjnY3TdU1RuS/Jfl3Ou6+3cf6IIBAFbdhhHV3UeSXHGvh29dN/7eJO/d4nUBAKw0H/sCADDwoL9jOcB2+KZvPDO7Hrb7VC8DHnLWvn5Xvnz73ad6GUlEFMDIroftzv96y5NP9TLgIeexb7wlyWpElMt5AAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYOCMjSZU1c4k1yY5L8nhJJd398F1429LcnGSry4femF3374NawUAWBkbRlSSS5Ps7u4Lq+qCJNckeeG68acmeU5337YN6wMAWEmbuZx3cZIbk6S7DyQ5/9jA8izVX07yjqraX1U/vC2rBABYMZuJqHOSrL88t1ZVx85g/YUkP5vkZUmem+Q1VXXu1i4RAGD1bOZy3h1J9qzb3tnd9yy/vjPJ27r7ziSpqpuyeO/U7xxvZ7t27cjevWcPlwucTrzWge2wKseWzUTU/iQvSHLd8j1Rt6wb+84kv1RVT8nirNbFSf7t/e1sbe1oDh26c7jcE7dv356NJwHb4mS+1k82xxY4dValIzYTUdcnuaSqbk6yI8llVXVlkoPdfUNV/UKSA0nuTvLu7v69LVgzAMBK2zCiuvtIkivu9fCt68avTnL1Fq8LAGCludkmAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgIEzNppQVTuTXJvkvCSHk1ze3QfvY85/SvK+7n77diwUAGCVbOZM1KVJdnf3hUmuSnLNfcx5a5JHbOG6AABW2mYi6uIkNyZJdx9Icv76war6oSRHjs0BAHgo2PByXpJzkty+bnutqs7o7nuq6klJXpLkh5K8cTNPuGvXjuzde/aJrxQ47XitA9thVY4tm4moO5LsWbe9s7vvWX798iSPSXJTkscl+XpV/UF3H/es1Nra0Rw6dOdwuSdu3749G08CtsXJfK2fbI4tcOqsSkdsJqL2J3lBkuuq6oIktxwb6O7XH/u6qt6U5A/vL6AAAB4sNhNR1ye5pKpuTrIjyWVVdWWSg919w7auDgBgRW0YUd19JMkV93r41vuY96YtWhMAwMpzs00AgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABg4Y6MJVbUzybVJzktyOMnl3X1w3fhrk7wiydEk/6y7r9uepQIArI7NnIm6NMnu7r4wyVVJrjk2UFWPSvJ3k1yU5PuTXFNVO7ZhnQAAK2UzEXVxkhuTpLsPJDn/2EB335bku7v77iSPTnJXdx/djoUCAKySzUTUOUluX7e9VlV/dhmwu++pqtclOZDkF7d4fQAAK2nD90QluSPJnnXbO7v7nvUTuvtfVtU7knygqp7R3b9xvJ3t2rUje/eePVstcFrxWge2w6ocWzYTUfuTvCDJdVV1QZJbjg1UVSX5mSR/O8ndWbzx/Mj97Wxt7WgOHbpzvOATtW/fno0nAdviZL7WTzbHFjh1VqUjNhNR1ye5pKpuTrIjyWVVdWWSg919Q1V9IslHsvjtvA90929uwZoBAFbahhHV3UeSXHGvh29dN/7mJG/e4nUBAKw0N9sEABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMHDGRhOqameSa5Ocl+Rwksu7++C68R9N8qLl5n/u7jdvx0IBAFbJZs5EXZpkd3dfmOSqJNccG6iqJyR5aZKLklyQ5NlVde42rBMAYKVsJqIuTnJjknT3gSTnrxv7QpLndvdadx9NcmaSu7Z8lQAAK2bDy3lJzkly+7rttao6o7vv6e67k9xWVTuSXJ3kt7v70/e3s127dmTv3rPnKwZOG17rwHZYlWPLZiLqjiR71m3v7O57jm1U1e4k/ybJV5O8ZqOdra0dzaFDd57oOsf27duz8SRgW5zM1/rJ5tgCp86qdMRmLuftT/L8JKmqC5LccmxgeQbqfUk+0d2v7u61B7ZUAIDTw2bORF2f5JKqujnJjiSXVdWVSQ4m2ZXk6UnOqqrnLee/obs/si2rBQBYERtGVHcfSXLFvR6+dd3Xu7d0RQAApwE32wQAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgIEzNppQVTuTXJvkvCSHk1ze3QfvNWdfkv1Jzu3uu7ZjoQAAq2QzZ6IuTbK7uy9MclWSa9YPVtVzkvzXJI/e8tUBAKyozUTUxUluTJLuPpDk/HuNH0nyrCRf3tqlAQCsrg0v5yU5J8nt67bXquqM7r4nSbr715Kkqjb1hLt27cjevWef6DqB05DXOrAdVuXYspmIuiPJnnXbO48F1MTa2tEcOnTn9NtP2L59ezaeBGyLk/laP9kcW+DUWZWO2MzlvP1Jnp8kVXVBklu2ZlkAAKevzZyJuj7JJVV1c5IdSS6rqiuTHOzuG7Z1dQAAK2rDiOruI0muuNfDt97HvMdt0ZoAAFaem20CAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMCAiAIAGBBRAAADIgoAYEBEAQAMiCgAgAERBQAwIKIAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMCCiAAAGRBQAwICIAgAYEFEAAAMiCgBgQEQBAAyIKACAAREFADAgogAABkQUAMDAGRtNqKqdSa5Ncl6Sw0ku7+6D68ZfmeTVSe5J8tbufv82rRUAYGVs5kzUpUl2d/eFSa5Kcs2xgap6dJK/n+R7kzwnyc9U1VnbsE4AgJWymYi6OMmNSdLdB5Kcv27sryXZ392Hu/v2JAeTnLvlqwQAWDGbiahzkty+bnutqs44zthXk3zjFq0NAGBlbfieqCR3JNmzbntnd99znLE9SQ7d387OPHPXbfv27fn8iSzygfrY1S8/mU8HLO3bt2fjSaexx77xllO9BHhIOsnHlr94vIHNRNT+JC9Icl1VXZBk/VHjo0l+qqp2JzkryROT/O4G+9u3iecEAFhpO44ePXq/E9b9dt65SXYkuSzJ85Mc7O4blr+d96osLg3+dHf/yvYuGQDg1NswogAA+PPcbBMAYEBEAQAMiCgAgIHN/HYenJCqen2SH03y+O6+615jVyR5dHe/6Tjf+4okb0ny2SS7khxJ8vLufsC3xaiqb0ry3O5+zwPdFzBXVd+X5Lokn0xyNIt7Dn42yUu7++vDfb43ydu7+4PD739ckt9J8vF1D9/U3W+Z7O9+nuexSc7r7l/dyv1yaogotsPLkrw3yYuSvGvw/e/p7quSpKpeleTHkrxuC9Z1bpK/mUREwal3U3e/6NhGVb0ni9fnL5+6JeWT3f192/wcz0zyV5KIqAcBEcWWWv6E+Zkkb0/yi0neVVUXJ3lbkq9k8UHVB5ZzfyaLjxF6ZJJPdPdl97HLRyT54+X8S5K8NcldSb6U5Ie7+1BVXZPFxxMliwB7W1X9YJIfT3J3kv+TRdD9RJLzqupV3f2Orf67AzNV9bAk35rkK1X1ziTfvty+obt/sqreleRwksctH39Fd3+8ql6b5PIk/zfJNy/3dWaSn0/yhCzOZv/z7v6lqvpgkk8keVKSryX5cBaf+bo3ybM3WN99HWPelcWx65FJ/kaS1yf56+ue899X1WuS/J0szqj/VhZn6K9KcnZV3dzdNwz/lbEivCeKrXZ5knd2dyc5XFVPS/JzSV7c3c9K8rkkqapzknyluy/JIqQuqKrHLPfxkqr6YFX9zyRvSPK+qtqR5B1JfrC7n57kN5P8ZFX9QJLHJ7kgi4PcS6rqyUlenOTq7r44yfuzuFzwU1n89Cug4NR75vJ1/sksLqFdn8UPYAe6+zlZfDbrFevmf375+M8meVVVfUuSf5DFa/+FSR62nPfqJF/s7ouSPCvJW6vqUcuxj3b392dxc+g7l8efTyZ5+nL8u5ZrOvbPY+7nGJMsjicXLccevzzePCPJT1TV3izuq/i67r4wyaeyuNfiP80ixATUg4AzUWyZqnpEFjdi/eaq+ntZfI7i65J8S3d/ejltf5K/lORPl/P+XRY/FX5DkjOXc9Zfzntmkl9JcmGSO7r7fy/nfCjJTyf5oyQf7u6jSe6uqgNJvivJlUnesFzHp5L8x237iwMTN3X3i6rqkUl+LYsfsL6c5Huq6hlZfKzYWevm//byzy8k+d4k35Hk97r7cJJU1UeX409M8utJ0t1fXUbadyzHjr3f6VAW8ZQszpDvXn795y7nVdVLct/HmCTp5Z9PTvLU5dmuZHEse1wWEfUPq+rxST6SRUTxIOJMFFvpZUn+dXc/u7ufm+RpWZwm/5OqeuJyzvcs/3xekm/v7hcn+UdJHp77PsB8IYufMG9Lck5Vfevy8acn+XQWgXRx8men8S9K8vtZ3EX/TcuzVjuS/K0sTqn7fx5WSHd/KYtjxzuzuNx1qLtfmuSaLC57HTsu3PvO0L+f5K9W1cOraleSpywf/1QWl9VSVXuyCJzPHWcfm3G8Y0yyOKYkya1JfmMZYM/M4k3zn0nyyiRXLI9DT1l+r+PQg4j/kGyly5P8wrGN7r4zi7NIP5/k3VX13/L/P8jxo0meUFUfyuKNpJ9N8m3LsWOX8349i/dVXbH8KfCVSf5DVe3P4jT9P+nu9yf5XFV9JIv3Wv1yd398uf/3L5/z0Vlc0vtMkidX1Y9s278B4IR19yeT/Iss3q/03OVx4eeyiJVvO873fDGLS2M3J/lAkj9ZDr0jySOr6r8n+WCSN3f3Hz+AtR3vGLPeryb5WlV9OMnHkhzt7q9m8VmzH66qm7J4b+f/WD72wqp6UTjt+dgXAIABZ6IAAAZEFADAgIgCABgQUQAAAyIKAGBARAEADIgoAIABEQUAMPD/AOdFL8LTRJqEAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaboost_accuracy=adaBoostClassifier.score(mixed_test_dataset,mixed_y_test)\n",
    "rf_accuracy=randomForestClassifier.score(mixed_test_dataset,mixed_y_test)\n",
    "print(f'AdaBoostClassifier accuracy for the mixed data= {adaboost_accuracy}')\n",
    "print(f'RandomForestClassifier accuracy for the mixed data = {rf_accuracy}')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(x=['AdaBoost','RandomForest'],y=[adaboost_accuracy,rf_accuracy],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We can notice that in Adaboost the accuracy has been decreased from 0.94 to 0.60 .\n",
    "### and in Random forest the accuracy has been decreased from 0.99 to 0.59.\n",
    "## So, our generation is good and scammed the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Consider the Discriminator to as the first level classifier and RF/Adaboost as the second level classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Because of our discriminator is trained on scaled data, so we will scale this data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.25756439,  0.87078121,  0.53914657, ...,  0.8       ,\n         0.        ,  0.85363261],\n       [ 0.052013  ,  0.4764824 ,  0.72794642, ...,  0.32857143,\n         0.        ,  0.4878012 ],\n       [ 0.91322831,  0.78044984,  0.70242734, ...,  0.47142857,\n         1.        ,  0.7804762 ],\n       ...,\n       [ 0.72875177,  0.45394682,  0.46190717, ...,  0.47989932,\n        -0.02669582,  0.58812335],\n       [ 0.37069305,  0.37663538,  0.41486147, ...,  0.13730196,\n        -0.12430178,  0.55329003],\n       [ 0.47329716,  0.4897643 ,  0.60431999, ...,  0.32724212,\n         0.25948471,  0.76374014]])"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_test_dataset_scaled=scaler.transform(mixed_test_dataset)\n",
    "mixed_test_dataset_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concat the labels as one hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4897, 14), dtype=float64, numpy=\narray([[0.25756439, 0.87078121, 0.53914657, ..., 0.85363261, 0.        ,\n        1.        ],\n       [0.052013  , 0.4764824 , 0.72794642, ..., 0.4878012 , 1.        ,\n        0.        ],\n       [0.91322831, 0.78044984, 0.70242734, ..., 0.7804762 , 1.        ,\n        0.        ],\n       ...,\n       [0.72875177, 0.45394682, 0.46190717, ..., 0.58812335, 1.        ,\n        0.        ],\n       [0.37069305, 0.37663538, 0.41486147, ..., 0.55329003, 1.        ,\n        0.        ],\n       [0.47329716, 0.4897643 , 0.60431999, ..., 0.76374014, 1.        ,\n        0.        ]])>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_examples_for_mixed_dataset = keras.utils.to_categorical(mixed_y_test, 2)\n",
    "mixed_test_dataset_scaled_and_labels = tf.concat([mixed_test_dataset_scaled, one_hot_examples_for_mixed_dataset], 1)\n",
    "mixed_test_dataset_scaled_and_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect the real and fake tasks using the discriminator as first level classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "trained_critic=wgan.discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  0\ncount  12587.000000\nmean      -0.915395\nstd        0.187839\nmin       -1.596453\n25%       -1.040667\n50%       -0.911122\n75%       -0.786402\nmax       -0.337110",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12587.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.915395</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.187839</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.596453</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.040667</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.911122</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-0.786402</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-0.337110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligitimate_tasks=df[df['Ligitimacy']==1]\n",
    "ligitimate_tasks_without_labels=ligitimate_tasks.drop('Ligitimacy',axis=1)\n",
    "ligitimate_tasks_without_labels=scaler.transform(ligitimate_tasks_without_labels)\n",
    "ligitimate_tasks_without_labels=tf.concat([ligitimate_tasks_without_labels,keras.utils.to_categorical([1]*ligitimate_tasks_without_labels.shape[0], 2)],axis=1)\n",
    "ligitimate_tasks_without_labels=pd.DataFrame(ligitimate_tasks_without_labels)\n",
    "ligitimate_tasks_pred=pd.DataFrame(trained_critic.predict(ligitimate_tasks_without_labels))\n",
    "ligitimate_tasks_pred.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 0\ncount  1897.000000\nmean     -0.628636\nstd       0.204406\nmin      -1.232015\n25%      -0.778623\n50%      -0.646811\n75%      -0.444343\nmax      -0.203142",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1897.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.628636</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.204406</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.232015</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.778623</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.646811</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-0.444343</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-0.203142</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligitimate_tasks=df[df['Ligitimacy']==0]\n",
    "ligitimate_tasks_without_labels=ligitimate_tasks.drop('Ligitimacy',axis=1)\n",
    "ligitimate_tasks_without_labels=scaler.transform(ligitimate_tasks_without_labels)\n",
    "ligitimate_tasks_without_labels=tf.concat([ligitimate_tasks_without_labels,keras.utils.to_categorical([0]*ligitimate_tasks_without_labels.shape[0], 2)],axis=1)\n",
    "ligitimate_tasks_without_labels=pd.DataFrame(ligitimate_tasks_without_labels)\n",
    "ligitimate_tasks_pred=pd.DataFrame(trained_critic.predict(ligitimate_tasks_without_labels))\n",
    "ligitimate_tasks_pred.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wgan_gp",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}