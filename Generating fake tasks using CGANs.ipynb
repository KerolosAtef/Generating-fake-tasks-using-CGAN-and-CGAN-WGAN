{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import important libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "-8427_tP1JEW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download MCS dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "# !gdown --id 11_0c5fvFpydBb0-pWCDcxzp3-ZiUtKGX"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "         ID   Latitude  Longitude  Day  Hour  Minute  Duration  RemainingTime  \\\n0         1  45.442142 -75.303369    1     4      13        40             40   \n1         1  45.442154 -75.304366    1     4      23        40             30   \n2         1  45.442104 -75.303963    1     4      33        40             20   \n3         1  45.441868 -75.303577    1     4      43        40             10   \n4         2  45.447727 -75.147722    2    15      49        30             30   \n...     ...        ...        ...  ...   ...     ...       ...            ...   \n14479  3999  45.445303 -75.165596    2     1      18        20             20   \n14480  3999  45.445574 -75.165168    2     1      28        20             10   \n14481  4000  45.436682 -75.152416    0    12      21        30             30   \n14482  4000  45.436978 -75.153278    0    12      31        30             20   \n14483  4000  45.436983 -75.153240    0    12      41        30             10   \n\n       Resources  Coverage  OnPeakHours  GridNumber  Ligitimacy  \n0              9        91            0      131380           1  \n1              9        91            0      131380           1  \n2              9        91            0      121996           1  \n3              9        91            0      121996           1  \n4              5        47            0      140784           1  \n...          ...       ...          ...         ...         ...  \n14479         10        80            0      131397           1  \n14480         10        80            0      131397           1  \n14481          4        63            0      122015           1  \n14482          4        63            0      122015           1  \n14483          4        63            0      122015           1  \n\n[14484 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n      <th>Ligitimacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>45.442142</td>\n      <td>-75.303369</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>40</td>\n      <td>40</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>45.442154</td>\n      <td>-75.304366</td>\n      <td>1</td>\n      <td>4</td>\n      <td>23</td>\n      <td>40</td>\n      <td>30</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>131380</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>45.442104</td>\n      <td>-75.303963</td>\n      <td>1</td>\n      <td>4</td>\n      <td>33</td>\n      <td>40</td>\n      <td>20</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>45.441868</td>\n      <td>-75.303577</td>\n      <td>1</td>\n      <td>4</td>\n      <td>43</td>\n      <td>40</td>\n      <td>10</td>\n      <td>9</td>\n      <td>91</td>\n      <td>0</td>\n      <td>121996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>45.447727</td>\n      <td>-75.147722</td>\n      <td>2</td>\n      <td>15</td>\n      <td>49</td>\n      <td>30</td>\n      <td>30</td>\n      <td>5</td>\n      <td>47</td>\n      <td>0</td>\n      <td>140784</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14479</th>\n      <td>3999</td>\n      <td>45.445303</td>\n      <td>-75.165596</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18</td>\n      <td>20</td>\n      <td>20</td>\n      <td>10</td>\n      <td>80</td>\n      <td>0</td>\n      <td>131397</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14480</th>\n      <td>3999</td>\n      <td>45.445574</td>\n      <td>-75.165168</td>\n      <td>2</td>\n      <td>1</td>\n      <td>28</td>\n      <td>20</td>\n      <td>10</td>\n      <td>10</td>\n      <td>80</td>\n      <td>0</td>\n      <td>131397</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14481</th>\n      <td>4000</td>\n      <td>45.436682</td>\n      <td>-75.152416</td>\n      <td>0</td>\n      <td>12</td>\n      <td>21</td>\n      <td>30</td>\n      <td>30</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14482</th>\n      <td>4000</td>\n      <td>45.436978</td>\n      <td>-75.153278</td>\n      <td>0</td>\n      <td>12</td>\n      <td>31</td>\n      <td>30</td>\n      <td>20</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14483</th>\n      <td>4000</td>\n      <td>45.436983</td>\n      <td>-75.153240</td>\n      <td>0</td>\n      <td>12</td>\n      <td>41</td>\n      <td>30</td>\n      <td>10</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>122015</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>14484 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MCSDatasetNEXTCONLab.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the dataset into training dataset (80%) and test dataset (20%)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "(2897, 12)"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Ligitimacy']\n",
    "X = df.drop(['Ligitimacy'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=seed, stratify=y)\n",
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement classic classifiers (Adaboost and RF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "adaBoostClassifier = AdaBoostClassifier()\n",
    "randomForestClassifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the balance of the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "1    10069\n0     1518\nName: Ligitimacy, dtype: int64"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### So, we should upsample the dataset to make it balanced and train a good classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=seed)\n",
    "X_train_smoted, y_train_smoted = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Adaboost and RF via training dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost training classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10069\n",
      "           1       0.97      0.93      0.95     10069\n",
      "\n",
      "    accuracy                           0.95     20138\n",
      "   macro avg       0.95      0.95      0.95     20138\n",
      "weighted avg       0.95      0.95      0.95     20138\n",
      "\n",
      "RandomForest training classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10069\n",
      "           1       1.00      1.00      1.00     10069\n",
      "\n",
      "    accuracy                           1.00     20138\n",
      "   macro avg       1.00      1.00      1.00     20138\n",
      "weighted avg       1.00      1.00      1.00     20138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## fit models on training data\n",
    "adaBoostClassifier.fit(X_train_smoted,y_train_smoted)\n",
    "randomForestClassifier.fit(X_train_smoted,y_train_smoted)\n",
    "\n",
    "y_pred_train_adaBoost = adaBoostClassifier.predict(X_train_smoted)\n",
    "y_pred_train_randomForest = randomForestClassifier.predict(X_train_smoted)\n",
    "print('AdaBoost training classification report')\n",
    "print(classification_report(y_train_smoted, y_pred_train_adaBoost))\n",
    "print('RandomForest training classification report')\n",
    "print(classification_report(y_train_smoted, y_pred_train_randomForest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verify detection performance using test dataset and present results comparison in bar chart\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost testing classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       379\n",
      "           1       0.99      0.93      0.96      2518\n",
      "\n",
      "    accuracy                           0.93      2897\n",
      "   macro avg       0.82      0.92      0.86      2897\n",
      "weighted avg       0.94      0.93      0.93      2897\n",
      "\n",
      "RandomForest testing classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       379\n",
      "           1       1.00      1.00      1.00      2518\n",
      "\n",
      "    accuracy                           0.99      2897\n",
      "   macro avg       0.99      0.98      0.99      2897\n",
      "weighted avg       0.99      0.99      0.99      2897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_adaBoost = adaBoostClassifier.predict(X_test)\n",
    "y_pred_test_randomForest = randomForestClassifier.predict(X_test)\n",
    "print('AdaBoost testing classification report')\n",
    "print(classification_report(y_test, y_pred_test_adaBoost))\n",
    "print('RandomForest testing classification report')\n",
    "print(classification_report(y_test, y_pred_test_randomForest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "{'AdaBoost_Testing_Accuracy': 0.9257852951328961,\n 'Random_Forest_Testing_Accuracy': 0.9937866758715913}"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_Testing_Accuracy = accuracy_score(y_pred_test_adaBoost, y_test)\n",
    "Random_Forest_Testing_Accuracy =accuracy_score(y_pred_test_randomForest, y_test)\n",
    "acc_dict = {'AdaBoost_Testing_Accuracy':AdaBoost_Testing_Accuracy,\n",
    "            'Random_Forest_Testing_Accuracy':Random_Forest_Testing_Accuracy}\n",
    "acc_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAJMCAYAAAArP6gWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo8UlEQVR4nO3debit93z//9fJQIgTY0y9KKXeX4SYJRFTKyoo4astYkobEaWtoYiah2qLtIZfYyiiitIqlVJRQ2MIiakIkbemSH2rWkpCKiI5Ob8/7nvLdrLPOTtx1udsO4/HdZ3r7H3fa93rs+6919rP9bnvvfaGzZs3BwCAxdtlZw8AAODSQngBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGCQ3Xb2AGA9qardk5yR5PPdfY+tXOYBSR7b3XfZzra+luTcJOdkepG0a5KXdverd+SY59u6V5Lbd/czt1j+rCQHdPevbLH81knek+Q6Sa6S5CVJbpJk8zzeF3T3O1e4nUckeWmSr86LNiTZK8lHkhzR3T/cQffnXUne1t2v3xHb28btPDvJY5L8xxarDu/uTy34tv8iySu7+9NbWf93Se6c5Lrd/YNFjuWSqqrnJjm9u9+ws8cCowgv2LHul+TzSW5dVTfu7i/9lNs7dOkHeFVdJ8mXq+o93f31n3agW7htpoDa0quTPLWqrrPFbR6R5DXdfW5VvSbJ+7v7N+Zx3iTJiVV1wFbu/0e6+95Ln1TVHkk+muThSV61g+7PSG/t7sfuhNs9KFvZX1V17SR3SnJSkocleeXAca3alqEPlwbCC3as307yliSnJ3lckkclP35lf2iS/0nyr0sXrqobJfnzJFdIcu0kn03yG1uZ+blykv9NcvZ83TsmeVGSyyf5UZKnd/fx87pnJHlQkvOTfDnTDNs3q+r+SZ6e5IIkm5I8KdOs2pFJdq2qs7r7aUs32N3/WVXHJXlEkufN275Ckl9Psu98sWsluVxV7dLdF3T3qVV1nyTfXeU+u2qSKyb5zrz9eyf5gySXSXL1JH/Z3c+oqrsk+cMkX0myT5LLJnlMd//zHBp/Oe/DM+brLe3jFffTPPv2f5NcLsn1kvx7pq/FY5PcKMmfdvfRq7wPFzHPfv5pkl/OtK9PTvL47v7+PJt5cpKbz/f1E0n+vyTXTbJ7krd09wuqarckL09y4Dz2ryQ5LMlT5/v6pqp6WHefvMXNH5HkA0neluR5VfWq7t48j+v2SV6WZM95m7/f3R/cxvLNSfbu7m/P19+cZO9MX4OXZvqe3DPJ7ZK8MMl+STZmms08vLtPnL9nXp7kDpm+J/8+ydOSHJvkC9394qq68by9q2aa3X1Zd79uvu6xSX4x0/ftp5M8qrsvuARfFtjpnOMFO8g807Nfkr/JFAEPraqrVtV9M/2Av0WSAzJFxpJHZgqL/ZPcMMn1k9xr2fo3VdVnq+q0JP+S6dDSd6vqqpl+qP5ed98802zRG6vq+lV1WJKDk9x2XveFJK+ft/eiJL/d3bdJ8owkd5l/aL8y08zN03JRf57ksKraMH/+oCQndPe/z5//fqZY+e+qemdVPSnJV7r7m1vZVXec79OXqupb8/56cXf/7XwbT0zy8HmM+2WacbvafN3bJzm6u2+Z5LVJnr1sjCd1902T/G6S/5Mk29pPS2PJFDI3SnKNJA/MFEr3TPL8qlrNc+RvzPdn6d/SLM7TM8XRvvO/XTLt/yVf6O4bd/c7kvxVktd1960zBczdqurXk+yf5C5Jbj6v+8r88dOSfCPTjOhPRNcca49M8sYk/zDfr3vM63bPFD3P7e595su9tKouu5Xl27v/+yR5UHfvm+RW8/3dv7tvkukxcNR8uecm2SPJjTM9Du6Q6TDo8jG/LclR8/28c5Lfr6r9Ms0ib+zuW2SamU2SX9jOuGDNEl6w4zw6ybu7+zvd/clM5zE9Ksndkry9u7/f3ecned2y6zwlybeq6slJXpHpB9cVlq0/tLtv0d3/J9P5VA+oqgdlCpDTl37odvcXk5yY6Yf0wUmO7e7/nbfx0iS/XFWXyTQb94758OCVM81QbFN3fyjJD5LcdV50RKbQWVr/wUwzNYdkmsX51SSnVdVts7KPzD9Eb5ppFuRqSd45b2vzfP1bz+eX/WmmmZM95+ue0d2fnT/+TC48PHq3zHHZ3acn+eC8fFv7KUk+2d1fn2dPvprkn+aP/y1TKFx+e/snU7DeYtm/587LD84UyufN23z5vOzH+yFJqmrPTKHxvKr6bKbDg9fNFCinZJ4tq6rnJfm77v7YdsZz30wzRsd397mZvuaPn9fdLMmm7n73vD8+3d03y/S1uMjyVcwqfb27z5iv8/FMsfmoqnpxkgfkwu/luyV5bXdv6u4fdfedu/uEZdu5UZIbJHndvA8+lGkm8paZDkPftKpOyBRyL5m/xvAzSXjBDjD/8HxYkgOr6mvzoaRrZTrxerdM8bDk/GUf/3WmkDkjyZ9lionll/2x7v5GkuMynbuz0mN3l0yHqbZct8vSGOaZkjsk+VSmw4cfX+WszjFJfquqbpHkCt39/vl+X72qjkmyubs/2t0v6O47JXlrptmlrZoPSz43U/C8dt7enplm9m6VaV88Kcl5uXCfnLNsE5uXLV/+cXLhPt7Wfkqmw6zLnbetMV9MK30ddl/2+dnz/7tmGvsBS/GWaabvBd19ZqbZst/PFGBvrarHZ9senSlaTp+/Dw9JclBV3TTTftm8/MJVtc/Wls8zUZnHlznelzt72eXvleTd86fvzDSLuvQ1+YntV9V15tnIJbsmOXN5wM774Nju/mqm2eA/yvSLGO+ff0EFfiYJL9gxDk3y7STX7u7rdff1Mh0OuUKmV+y/VlVXmiPnocuu9yuZDu+8NdMPpttn+iF0EXOUHJTpfKCTpkV1u3ndTTMF2QlJ3pvp0ODSLNHvJvlwkk3zD+I9u/uVmc5Hu3GmGDg/PxkFW/qrJL80X+eYZcu/M4/p95YORVbV5TPN2HxmG9tb7jGZZuQOyXQez16ZzsP6h0wzQZfNVvbJMsdnCthU1XVz4ezctvbTor03yZFVtfv8dX9MkvdteaHu/t48zifMY7xSplm5+87nu30gyce6+9lJ3pALz627yNdsPmfwLklutfR92N3XzjS79rgknWRzVR00X/5WmWYHt7Z8lyTfSnKb+Sbuv437e1CSf+juVyT5ZKbgW/q6vT/Jw6tql/mw5tuy7FDjfPs/rKqHzLd/nUyHyG9dVY/OdI7XP3X3U+b9us82xgFrmvCCHePRmU7G3rS0YJ6teFmmH3ivyzTLdHKSs5Zd7w8yHfr7VKYZgg9lenW/ZOkcr3/JNBP0ru4+dj7R+deSvLyqTkny5iSHdfeXM80evT/JJ6rqS5lmjw6dD3M+Lsmbq+ozSf42yW/Oh6M+kOQ+VfXyle5cd38/yduT/Eamc3eWlp+f5O6ZzkX6alV9Yb6P7+3u1620rRW2/W9J/iTTYcUvJ3lXpkOVn0lynySnbrFPVvKYJDeZ7+9rM/2SQraznxbt+Um+OY/lS5ki6fe2ctkHJ9lvHuPJSf66u9+U6S07vpjkC/P3yAG58Ly2v880A3b3Zdt5dJJ3zPt0ueckeUimk97vn+RZ8yG9Vya5//w9sNLyH2UK9z+fvx63TPKfW7kPr0xy56r6fJKPZzpce/05Op+T6YT9z2X6Pv7H7n770hXn27lvksPn6/9Tkmd094mZYnPXJKfO+2CvTIfP4WfShs2bN2//UgAA/NS8nQTAVlTVXTOde7eSf+7u7Z1vBfATzHgBAAziHC8AgEGEFwDAID8T53hdcMEFmzdtckiU1dl11w3x/QLsaJ5bWK3dd9/125n+tNZF/EyE16ZNm3PmmT/Y2cPgZ8SVrnR53y/ADue5hdXae++NZ2xtnUONAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDLCy8qur2VXXCCst/tao+WVUfr6pHLur2AQDWmoWEV1U9OclrkuyxxfLdk/xZkrsnuXOSI6rqGosYAwDAWrOoGa9/S3L/FZbfOMnp3f3d7v5Rko8mudOCxgAAsKYsJLy6+++SnLfCqr2SnLXs8+8nueIixgAAsNaMPrn+e0k2Lvt8Y5IzB48BAGCn2G3w7X0pyS9W1VWSnJ3pMOOLB48BAGCnGBJeVfXgJFfo7ldX1ROSvDfTbNvruvs/RowBAGBn27B58+adPYbtOu+8TZvPPPMHO3sY/Iy40pUuH98vrEVXueLu2fUye2z/gsAOtelHP8x3zlrp1PPF2HvvjZ9OcpuV1o0+1AhwqbXrZfbIvz/3Zjt7GHCpc91nnpKVf+dvPO9cDwAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhkt509gLXoCnvtkctddvedPQx+CnvvvXFnD4FL4Jxzz8vZ3/vhzh4GwMIIrxVc7rK759ZPesPOHgZc6nz6RQ/L2RFewPrlUCMAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAMIrwAAAYRXgAAgwgvAIBBhBcAwCDCCwBgEOEFADCI8AIAGGS3RWy0qnZJckySfZOcm+Tw7j592fonJnlwkguSvKC737GIcQAArCWLmvE6JMke3b1/kqOSHL20oqqulOT3kuyf5O5JXrKgMQAArCmLCq8DkxyfJN19UpLbLFv3v0nOSLLn/O+CBY0BAGBNWVR47ZXkrGWfb6qq5Yc1v57k1CSfSfKyBY0BAGBNWVR4fS/JxuW3093nzx8fnORaSa6f5LpJDqmq2y1oHAAAa8aiwuvEJPdMkqraL8kpy9Z9N8k5Sc7t7h8mOTPJlRY0DgCANWMhv9WY5B1JDqqqjyXZkOSwqnpCktO7+7iquluSk6rqgiQfTfK+BY0DAGDNWEh4dfcFSY7cYvFpy9Y/K8mzFnHbAABrlTdQBQAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMMhui9hoVe2S5Jgk+yY5N8nh3X36svUHJ3lWkg1JPp3kMd29eRFjAQBYKxY143VIkj26e/8kRyU5emlFVW1M8qIk9+7u2yf5WpKrLWgcAABrxqLC68AkxydJd5+U5DbL1h2Q5JQkR1fVR5L8V3d/a0HjAABYMxYVXnslOWvZ55uqaumw5tWS3DXJU5IcnORxVXWjBY0DAGDNWFR4fS/JxuW3093nzx//T5JPdvc3u/vsJB9OcosFjQMAYM1YVHidmOSeSVJV+2U6tLjkM0n2qaqrzbNg+yU5dUHjAABYMxbyW41J3pHkoKr6WKbfXDysqp6Q5PTuPq6qnprkvfNl/6a7v7CgcQAArBkLCa/uviDJkVssPm3Z+rckecsibhsAYK3yBqoAAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAG2W54VdVlRgwEAGC9W82M16eq6iVVtc/CRwMAsI7ttorL3CLJPZI8q6r2TvLGJG/p7rMXOTAAgPVmuzNe3X1BkvckeV2S/0nyO0neW1WPXfDYAADWldWc4/XCJKcluV+SP+nufZPcMclvLXhsAADrymrO8frXJLfq7iOS/Evy41mw+y1yYAAA681qwmtDkmfPH7+7qh6aJN39tQWNCQBgXVrNyfVHJrnd/PG9knw4yV8tbEQAAOvUama8NnX3+UnS3ecl2bzYIQEArE+rmfF6Z1V9JMknktwqyXGLHRIAwPq03fDq7udX1buSVJI3dPfnFj8sAID1ZzVvJ3HDJAdnCq9DqupVCx8VAMA6tJpzvN48/39gkusnuerihgMAsH6tJrzO7u4/SvL/uvsRSa6x2CEBAKxPqwmvzVV1zSQbq2rPJFdY8JgAANal1YTXc5Ickum9u76S5AOLHBAAwHq1mreTuF13v3j+2FtJAABcQquZ8bpnVe268JEAAKxzq5nx2jvJN6rqq5netX5zdx+w2GEBAKw/qwmvey98FAAAlwKrCa+Hr7DsuTt6IAAA691qwuu/5v83ZPpbjas5LwwAgC2s5m81/sSfCKqq9yxuOAAA69d2w6uqbrTs02sl+fnFDQcAYP1azaHGV2X6bcYNSc5J8sSFjggAYJ1azflaByd5YnffNcmrk7x/sUMCAFifVhNeb0xyi/njGyX5y4WNBgBgHVtNeP1cdx+bJN39wkzneQEAcDGtJrw2L51gX1U3SOLPBwEAXAKrObn+8UneWlXXSPKNJEcudkgAAOvTama8PpvkN7v72kmen+RzCx0RAMA6tZrwelOcXA8A8FNzcj0AwCAX9+T6G8bJ9QAAl8jFPbn+nCSvX+iIAADWqe3OeHX3yUkelekd6/dMco1FDwoAYD3a6oxXVV0myYOSPCbJuUn2SnL97j5n0NgAANaVbc14fS3JzZMc2t13TPIN0QUAcMlt6xyvlyQ5NMn1quo1STYMGREAwDq11Rmv7n5hd++b5GVJHpzktlX1J1W1z7DRAQCsI6s5uf5D3f3QJDdI8v+S/NXCRwUAsA6t5u0kkiTdfWaSl8//AAC4mFbzBqoAAOwAwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAG2W0RG62qXZIck2TfJOcmOby7T1/hMu9O8s7ufuUixgEAsJYsasbrkCR7dPf+SY5KcvQKl3l+kisv6PYBANacRYXXgUmOT5LuPinJbZavrKoHJLlg6TIAAJcGiwqvvZKctezzTVW1W5JU1T5JHpzkmQu6bQCANWkh53gl+V6Sjcs+36W7z58/fliSn0vywSTXS/Kjqvpad5v9AgDWtUWF14lJfjXJ31TVfklOWVrR3U9e+riqnp3km6ILALg0WFR4vSPJQVX1sSQbkhxWVU9Icnp3H7eg2wQAWNMWEl7dfUGSI7dYfNoKl3v2Im4fAGAt8gaqAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABhFeAACDCC8AgEGEFwDAIMILAGAQ4QUAMIjwAgAYRHgBAAwivAAABtltERutql2SHJNk3yTnJjm8u09ftv7xSR44f/qP3f2cRYwDAGAtWdSM1yFJ9uju/ZMcleTopRVV9QtJDk1yQJL9kty9qm6+oHEAAKwZiwqvA5McnyTdfVKS2yxb9/Uk9+juTd29OcnuSX64oHEAAKwZCznUmGSvJGct+3xTVe3W3ed393lJvl1VG5K8KMm/dPeXFzQOAIA1Y1EzXt9LsnH57XT3+UufVNUeSd40X+a3FzQGAIA1ZVHhdWKSeyZJVe2X5JSlFfNM1zuTfK67H9XdmxY0BgCANWVRhxrfkeSgqvpYkg1JDquqJyQ5PcmuSe6c5LJVdfB8+ad298cXNBYAgDVhIeHV3RckOXKLxact+3iPRdwuAMBa5g1UAQAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADCK8AAAGEV4AAIMILwCAQYQXAMAgwgsAYBDhBQAwiPACABhEeAEADLLbIjZaVbskOSbJvknOTXJ4d5++bP0jkzwqyflJnt/d71rEOAAA1pJFzXgdkmSP7t4/yVFJjl5aUVXXTPK7Se6Q5FeS/FFVXXZB4wAAWDMWFV4HJjk+Sbr7pCS3WbbudklO7O5zu/usJKcnufmCxgEAsGYsKrz2SnLWss83VdVuW1n3/SRXXNA4AADWjIWc45Xke0k2Lvt8l+4+fyvrNiY5c1sb2333Xb+9994bz9ihI9yOT7/oYSNvDpjtvffG7V/oZ9h1n3nKzh4CXCoNfm75+a2tWFR4nZjkV5P8TVXtl2T5M80nkvxhVe2R5LJJbpzkC9vZ3t4LGSUAwEAbNm/evMM3uuy3Gm+eZEOSw5LcM8np3X3c/FuNR2Q61PmC7v67HT4IAIA1ZiHhBQDARXkDVQCAQYQXAMAgwgsAYJBF/VYja0BVPTnJ45Ncv7t/uMW6I5Ncs7ufvZXrPiLJc5N8JcmuSS5I8rDu/qnf1qOqrpLkHt395q2sPyjJ0+ZPD0jysfnjJ3b3p1ex/T2SPKS7XzPfj+9093E/7biXbX+r+xV+FlTVXZL8TZJTk2zO9P6KX0lyaHf/6BJu8y1JXtndJ+ygYS5t99lJHpzkG8sWP7m7P7GDb+d+SU7u7m9sZf2bkvxckusl+dE8nlO6+3dWuf07JTmzuz9fVW/v7vvvmJH/+Dnva0mO7u4X7ajtshjCa317SJK3JHlgktdfguu/ubuPSpKqOiLJk5I8dgeM6+ZJ7pNkxfDq7vcled98u9/s7rtczO1fM8nhSV7T3a+/5MPcqp92v8Ja8MHufuDSJ1X15kyPy7ftvCFt1Z929ysXfBu/l+TI/GTg/Vh3H5r8OAS/eQnG85uZnjc+vyOja/Z/520/oqqO7u4LdvD22YGE1zo1v6L9tySvTPLGJK+vqgOTvDTJdzP9gfKT5sv+UaY/63TVJJ/r7sNW2OSVk/z3fPmDkjw/yQ+T/E+S3+zuM6vq6Ex/LiqZou2lVXX/JE9Jcl6mJ7QHZprN2reqjujuV1+M+/RrSZ6QZFOSj3b3UVV1h0x/C/S8JD9I8oB5+zepqmdmOpz+zSSnzeP4UZJfSPKW7v7Dqrphpng6L8kZSa63rdBbab/Oy2+f5CXz7f1HkkMzBeaWy96T5MjuPm1p1nHexj/M+/Ifk5yc5Fnz9a6Q5MHd/eWqenqmv4O6W5JXZJqp+MXuflJV7Zrks0luaxaOi6uqLpPkWkm+W1WvSXKd+fPjuvvpVfX6JOdmmu25VpJHdPdnquoxmV7k/GeSq8/b2j3JsZkeZ7tmiqa3VtUJST6XZJ8kZyf5SKa/13ulJHfv7u9ezDFfL8nrMj0eNif53e7+XFWdkenxfmqSP03y6iSXS3JOprcx+lam2b4rJrl8pueL3ZPcIskbqurA1c76VdUVk7w203Nn5jGcUlXHJrnhfLsvncdyjyS3qqpTk3yiu68575PPzvtkryS/1t1nVNUzktxvHuvlkzxjOzOJhyd5XKavwT2TvKuqNiR5eaY/03eZTM8px62w7KxMz0kPnO/TN+exvX6+X1fN9L6cf5KLfl/8YpLXzNv6QaaZyROT3K67v1NVj06ysbtfuJr9eWnhHK/1a2nGp5OcO4fBK5I8qLvvluSrSVJVeyX5bncflCm+9quqn5u38eCqOqGqPpXkqUneOT+YX53k/t195yQfSvL0qrp3kusn2S9TfD24qm6W5EFJXtTdByZ5V6Ynlz/M9Gr74kTXVZI8J8kvz9v6uTkAD8n0JHrn+f5ded7+qd393C028/OZXhnul+TJ87IXZXovubtmesLYnpX2a5K8KlOA3j7JuzO9MfBKy7bmmpl++LwwyU0zHSq9S5K3J/m1qrplkoOT3D7Tk+aNkvx1kkPm6LpHkn8WXVwMvzQ/vk9N8pkk78j0ouKk7v6VTN9nRy67/Bnz8pcnOaKqrpFplmi/JPfN9MM3SR6V5FvdfUCSuyV5flVdbV73ie7+5Uxvnv2D+Xnn1EyP3215wjzWE6rq5fOyFyd5aXffaR7Ha+fl18n0YuXx82VeNj+WXpzkj5PcIMnVMsXEg5Ls1t3vzhRAD7uYh1r/IMkH5uePI5K8oqo2JrlTkvtnelxumk+ROD7TIdJ/32Ibn5ifk9+X5EFVtW+mx/ptMz2/XWtbA5jjZ8/u/lymEH3MvOqQJFfr7tsluWum5/eVlm3LB+ev48as/H3x4iR/1N37ZwrMfZO8KdML7GQ6OvCX27mNSx0zXutQVV0506ueq1fV72R6ZffYJNfo7i/PFzsx0yuyc+bL/XWmV6FXyPTqL/nJQ42/lOTvkuyf5Hvd/R/zZT6c5AVJ/ivJR7p7c5LzquqkJDfJNEP11HkcX0ry95fwbt0w018w+MeqSqYnghvMt/20JB/INKt0cqYn9ZWcMv/pqvOr6px52Y1z4TlkH8k0K7WibezXkzOdL/elJOnu186XX2nZ8k1uWPbxV5c94f9HkpdV1dmZzik5MUlleoLelGnG74nz9j6UadbgsEzn5MFqfbC7H1hVV830Q/+rSb6T5LZVdddMf95t+WPpX+b/v57kDpkef1/s7nOTpKqWzrm6cZL3J0l3f38OuxvM6z4z/39mpuBKphn4PbYz1pUONd440/NPuvuzVXWdefm3u/t/5o9vluQPquopmR5v53X3F6vqVZleuOye5GXbue1tuVmmgP2N+fOrzPf5cZleoO6VaWZ8W5bv12vO92vpsX7O/MJ3Ww5PsmdVHZ/pPh4wz+RXko8nyTyb+IyqOmqFZXfZYnvLn5d6/n9r3xfLb+O4JKmqTvKWqvpwkv/q7v/azvgvdcx4rU8PSfLa7r57d98j0yzJ3ZP8b1Utzbrcdv7/4CTX6e4HZXr1drn85ANvydczvaL9dpK9qmrpVdidk3w5U1QdmPz4UMMBSf4106vAZ8+zYxsyTZ9fkIv/vffVeQwHza9eX57pUOlDkrx+fsX5xfn2trb9ld4t+AuZYjKZXrlvy4r7tar2TvKN+ZVnquop84m6Ky37YS58BXurZdtefk7GXyQ5rLsfkenw7IZMh05uVVW7VNXuVfW+qrrsfNnDk1y9uz+/nfHDRcyR8pBMh4wen+kE8EMzHcK//DzLnVz08fOvSW5aVZebZ11vOS//UpI7Jsk8+3OzzDPsK2zjp7H8dm6R6ZSC5CcfS6clecr8nPGoJH87z8Rv7O57JXl4pueSpetd3Oel05L82bz9X0/yxvm58dbdfb8k90rywqrabRvb33KffDFT5OwyP8ZvucJ1kvz4ufaBSe7Y3feYZ6T+OMlvZ9o/t50vd8Wqeu9Wlv34Oamqfj7JVZbdxNK+fERW/r5Yvr1Dq+p3evoFrDMzvSB+bbgI4bU+HZ7kr5Y+6e4fZJqtOjbTOQwfyIV/wPMTSX5hfnXytky/2XTted3Socb3Z3rVduQ8o/XIJG+vqhMzHUp4Xne/K8lXq+rjmYLobd39mXn775pv85qZDjf+W5Kbza8KV6W7v5XpfI0PVdXJmYLxy/P2XzNv/5eSvCHTuWiXqao/WcWmn5LkqPn698l0rtfWbG2/PjLTk/rr5hmoW2Y6V2ulZS9Lcsz8hLfrVm7njUk+Mu/fjUmu3d2fzXSo4sQkH03ypu4+t7tPzjQb+KZV3FdYUXefmul7c58k95ifD16RKa6uvZXrfCvTD/mPZTp38X/nVa9OctWq+miSE5I8p7v/ewHD/v0kv7NsrL+1lcs8a34MviHJ5zPdp7vM1/vbJM+cL/uxTM+PV1lhO1vzh0l+fT5X6/hML+S+meSaVfWxTDOJL55n2k9O8sfLXvyuqLtPyfRccVKmw7/nZevPS7+a5NPd/Z1ly45N8tBMs47fnb8O7810vulxKyz7VJIz5+fV5+TCSF7uA1n5++JJmY5onJDpaMHS89BfZIri47d1Xy+t/MkgLtWq6tBMv0J+elUdnuSA7v7NnT2u1arp76KemORXuvt7O3s8wE+nqq6e5AHdfcw84/XFJL+0wrlha1ZNvwh1s+5+5nYvfCnkHC92mqq6T6ZzwLb00u5+x6BhfD3T+Qg/yHTu1G9V1TGZzk/b0sHdfc4Ky3eKqrp+plfEx4oufpZV1XUzzUht6UPd/azBY3l7fvJwW5Kc1d33HTSEb2c61PjJTIchX5NpBm2l/fPW7n7FoHGtSlW9INOJ+/fe2WNZq8x4AQAM4hwvAIBBhBcAwCDCCwBgEOEFADCI8AIAGER4AQAM8v8DWe+Lhg/meEIAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_acc_tup = sorted(acc_dict.items(),key=lambda item:item[1])\n",
    "acc_dict = {k:v for k,v in sorted_acc_tup}\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "sns.barplot(x = list(acc_dict.keys()), y=list(acc_dict.values()))\n",
    "plt.grid()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('AdaBoost VS Random_Forest Accuracies');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement Conditional GAN with Wasserstein loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.99249812, 0.24691239, 0.19038729, ..., 0.8       , 0.        ,\n        0.24385902],\n       [0.50187547, 0.8656828 , 0.48180773, ..., 0.07142857, 0.        ,\n        0.85362741],\n       [0.36184046, 0.76124423, 0.83948626, ..., 0.32857143, 0.        ,\n        0.7560968 ],\n       ...,\n       [0.28982246, 0.53945756, 0.47422468, ..., 0.65714286, 0.        ,\n        0.53656001],\n       [0.75743936, 0.67476991, 0.16140315, ..., 0.67142857, 0.        ,\n        0.68287282],\n       [0.03325831, 0.68059008, 0.16064208, ..., 0.04285714, 0.        ,\n        0.68287282]])"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_smoted_scaled = scaler.fit_transform(X_train_smoted)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_smoted_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants and hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_classes = 2\n",
    "take_size = 12\n",
    "latent_dim = 126"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create tensor Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=(TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "task_shape = (take_size + num_classes, 1)\n",
    "X_train_smoted = X_train_smoted.astype(np.float32)\n",
    "X_train_smoted_scaled = X_train_smoted_scaled.astype(np.float32)\n",
    "all_labels = keras.utils.to_categorical(y_train_smoted, 2)\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_smoted_scaled, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "n7BqV_T41JEa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 14, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 7, 64)             256       \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 7, 64)             0         \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 4, 128)            24704     \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 4, 128)            0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 4, 128)            0         \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 2, 256)            65792     \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 2, 256)            0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 2, 256)            0         \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 1, 512)            393728    \n",
      "                                                                 \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 1, 512)            0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 484,993\n",
      "Trainable params: 484,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x,filters,activation,kernel_size=2,strides=1,padding=\"same\",use_bias=True,use_bn=False,use_dropout=False,drop_value=0.5,):\n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "def get_discriminator_model():\n",
    "    img_input = layers.Input(shape=task_shape)\n",
    "    x = conv_block(img_input,64,kernel_size=3,strides=2,use_bn=False,use_bias=True,activation=layers.LeakyReLU(0.2),use_dropout=False,drop_value=0.3,)\n",
    "    x = conv_block(x,128,kernel_size=3,strides=2,use_bn=False,activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3,)\n",
    "    x = conv_block(x,256,kernel_size=2,strides=2,use_bn=False,activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=True,drop_value=0.3,)\n",
    "    x = conv_block(x,512,kernel_size=3,strides=2,use_bn=False,activation=layers.LeakyReLU(0.2),use_bias=True,use_dropout=False,drop_value=0.3,)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1,activation='sigmoid')(x)\n",
    "    d_model = keras.models.Model(img_input, x, name=\"discriminator\")\n",
    "    return d_model\n",
    "\n",
    "d_model = get_discriminator_model()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaqH7X0p1JEb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "8GmdwF1Q1JEc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4096)              524288    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 4096)             16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_35 (LeakyReLU)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 256)               1048576   \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,593,356\n",
      "Trainable params: 1,584,652\n",
      "Non-trainable params: 8,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def block(x,filters,activation,kernel_size=3,strides=1,padding=\"same\",use_bn=False,use_bias=True,use_dropout=False,drop_value=0.3,):\n",
    "    x = layers.Conv1D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias)(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "def get_generator_model():\n",
    "    noise = layers.Input(shape=(latent_dim+num_classes,))\n",
    "    x = layers.Dense(4 * 4 * 256, use_bias=False,activation='relu')(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(256, use_bias=False,activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(take_size,activation='leaky_relu')(x)\n",
    "    g_model = keras.models.Model(noise, x, name=\"generator\")\n",
    "    return g_model\n",
    "\n",
    "\n",
    "g_model = get_generator_model()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpLAmH171JEd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the CGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "wZReMVPk1JEd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CGAN(keras.Model):\n",
    "    def __init__(self,discriminator,generator,latent_dim,):\n",
    "        super(CGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(CGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_task,one_hot_labeld=data\n",
    "        if isinstance(real_task, tuple):\n",
    "            real_task = real_task[0]\n",
    "\n",
    "        real_task=tf.concat([real_task,one_hot_labeld],axis=1)\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_task)[0]\n",
    "\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim),seed=seed\n",
    "        )\n",
    "        random_latent_vectors=tf.concat([random_latent_vectors,one_hot_labeld],axis=1)\n",
    "\n",
    "        # Generate fake images from the latent vector\n",
    "        fake_task = self.generator(random_latent_vectors)\n",
    "        # Get the logits for the fake images\n",
    "        fake_task=tf.concat([fake_task,one_hot_labeld],axis=1)\n",
    "        combined_tasks = tf.concat(\n",
    "            [real_task,fake_task], axis=0\n",
    "        )\n",
    "\n",
    "         # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_tasks)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim),seed=seed)\n",
    "        random_latent_vectors=tf.concat([random_latent_vectors,one_hot_labeld],axis=1)\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_task = self.generator(random_latent_vectors, training=True)\n",
    "            generated_task=tf.concat([generated_task,one_hot_labeld],axis=1)\n",
    "\n",
    "            predictions = self.discriminator(generated_task)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Apply the provided training dataset to CGAN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPw5zmmC1JEf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "Al8UuPvA1JEf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "20/20 [==============================] - 9s 351ms/step - g_loss: 0.4883 - d_loss: 0.6710\n",
      "Epoch 2/8\n",
      "20/20 [==============================] - 7s 343ms/step - g_loss: 1.3779 - d_loss: 0.5935\n",
      "Epoch 3/8\n",
      "20/20 [==============================] - 7s 345ms/step - g_loss: 3.8624 - d_loss: 0.2981\n",
      "Epoch 4/8\n",
      "20/20 [==============================] - 7s 354ms/step - g_loss: 4.4488 - d_loss: 0.1425\n",
      "Epoch 5/8\n",
      "20/20 [==============================] - 7s 357ms/step - g_loss: 1.6385 - d_loss: 0.0283\n",
      "Epoch 6/8\n",
      "20/20 [==============================] - 7s 350ms/step - g_loss: 0.3710 - d_loss: 0.0162\n",
      "Epoch 7/8\n",
      "20/20 [==============================] - 7s 355ms/step - g_loss: 0.1803 - d_loss: 0.0119\n",
      "Epoch 8/8\n",
      "20/20 [==============================] - 7s 348ms/step - g_loss: 0.1096 - d_loss: 0.0110\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f7a0c7d4e0>"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of epochs for training.\n",
    "epochs = 8\n",
    "\n",
    "# Get the wgan model\n",
    "cgan = CGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=latent_dim,\n",
    ")\n",
    "\n",
    "# Compile the wgan model\n",
    "cgan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "# Start training\n",
    "cgan.fit(dataset, batch_size=batch_size, epochs=epochs,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate synthetic fake tasks via Generator network in CGAN after the training procedure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To faul the model we will generate unligitimate(milicious) tasks and label them as 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "num_of_tasks=2000\n",
    "trained_gen = cgan.generator\n",
    "one_hot_example = keras.utils.to_categorical([0]*num_of_tasks, 2)\n",
    "# Sample noise for the interpolation.\n",
    "fake_noise = tf.random.normal(shape=(num_of_tasks, latent_dim),seed=seed)\n",
    "# Combine the noise and the labels and run inference with the generator.\n",
    "noise_and_labels = tf.concat([fake_noise, one_hot_example], 1)\n",
    "fake = trained_gen.predict(noise_and_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 12)"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "              ID   Latitude  Longitude       Day      Hour     Minute  \\\n0    -571.647766  45.508526 -75.231567  0.464455  8.157324  15.363562   \n1    -707.057068  45.543427 -75.253136  2.126899 -0.225837  31.519039   \n2    -437.908325  45.535580 -75.260628  0.816118 -0.066987   5.977089   \n3    -200.460724  45.591099 -75.253296  1.006211 -0.845838   0.894647   \n4    -227.991348  45.537971 -75.235260  0.849303  1.017915  12.562887   \n...          ...        ...        ...       ...       ...        ...   \n1995 -444.878815  45.526932 -75.300354  0.836905 -1.133905  15.083454   \n1996 -273.710052  45.553280 -75.239441  2.016987  0.202000   6.865791   \n1997 -143.908173  45.538853 -75.241570  1.251927 -0.380992   1.363171   \n1998 -452.967377  45.521236 -75.309387  1.625790  3.966226  24.816416   \n1999 -384.522156  45.525143 -75.231346  1.285414 -1.103038  12.836702   \n\n       Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n0     70.693222      38.458027   6.308796  59.122658     0.480240   \n1     40.482040      31.859896   0.869059  47.446232     0.640747   \n2     40.335255      43.358593   0.836522  32.691059     0.536599   \n3     14.545959      48.160007  -0.408405  25.144382     0.469786   \n4     38.535370      50.703716   0.637425  40.800304     0.637392   \n...         ...            ...        ...        ...          ...   \n1995  17.918312      29.723480   0.382905  30.735096     0.497608   \n1996  23.347864      40.295158   0.284052  50.410530     0.466032   \n1997  17.889383      45.678703  -0.430957  28.103292     0.531100   \n1998  24.458256      43.193783   0.436114  43.095985     0.414003   \n1999  35.268780      37.536816   0.839387  40.914211     0.545149   \n\n         GridNumber  \n0     751750.062500  \n1     433531.906250  \n2     428903.812500  \n3      18337.121094  \n4     207623.250000  \n...             ...  \n1995  242898.890625  \n1996  204299.546875  \n1997  -23143.039062  \n1998   61672.214844  \n1999  206372.734375  \n\n[2000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-571.647766</td>\n      <td>45.508526</td>\n      <td>-75.231567</td>\n      <td>0.464455</td>\n      <td>8.157324</td>\n      <td>15.363562</td>\n      <td>70.693222</td>\n      <td>38.458027</td>\n      <td>6.308796</td>\n      <td>59.122658</td>\n      <td>0.480240</td>\n      <td>751750.062500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-707.057068</td>\n      <td>45.543427</td>\n      <td>-75.253136</td>\n      <td>2.126899</td>\n      <td>-0.225837</td>\n      <td>31.519039</td>\n      <td>40.482040</td>\n      <td>31.859896</td>\n      <td>0.869059</td>\n      <td>47.446232</td>\n      <td>0.640747</td>\n      <td>433531.906250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-437.908325</td>\n      <td>45.535580</td>\n      <td>-75.260628</td>\n      <td>0.816118</td>\n      <td>-0.066987</td>\n      <td>5.977089</td>\n      <td>40.335255</td>\n      <td>43.358593</td>\n      <td>0.836522</td>\n      <td>32.691059</td>\n      <td>0.536599</td>\n      <td>428903.812500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-200.460724</td>\n      <td>45.591099</td>\n      <td>-75.253296</td>\n      <td>1.006211</td>\n      <td>-0.845838</td>\n      <td>0.894647</td>\n      <td>14.545959</td>\n      <td>48.160007</td>\n      <td>-0.408405</td>\n      <td>25.144382</td>\n      <td>0.469786</td>\n      <td>18337.121094</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-227.991348</td>\n      <td>45.537971</td>\n      <td>-75.235260</td>\n      <td>0.849303</td>\n      <td>1.017915</td>\n      <td>12.562887</td>\n      <td>38.535370</td>\n      <td>50.703716</td>\n      <td>0.637425</td>\n      <td>40.800304</td>\n      <td>0.637392</td>\n      <td>207623.250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>-444.878815</td>\n      <td>45.526932</td>\n      <td>-75.300354</td>\n      <td>0.836905</td>\n      <td>-1.133905</td>\n      <td>15.083454</td>\n      <td>17.918312</td>\n      <td>29.723480</td>\n      <td>0.382905</td>\n      <td>30.735096</td>\n      <td>0.497608</td>\n      <td>242898.890625</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>-273.710052</td>\n      <td>45.553280</td>\n      <td>-75.239441</td>\n      <td>2.016987</td>\n      <td>0.202000</td>\n      <td>6.865791</td>\n      <td>23.347864</td>\n      <td>40.295158</td>\n      <td>0.284052</td>\n      <td>50.410530</td>\n      <td>0.466032</td>\n      <td>204299.546875</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>-143.908173</td>\n      <td>45.538853</td>\n      <td>-75.241570</td>\n      <td>1.251927</td>\n      <td>-0.380992</td>\n      <td>1.363171</td>\n      <td>17.889383</td>\n      <td>45.678703</td>\n      <td>-0.430957</td>\n      <td>28.103292</td>\n      <td>0.531100</td>\n      <td>-23143.039062</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>-452.967377</td>\n      <td>45.521236</td>\n      <td>-75.309387</td>\n      <td>1.625790</td>\n      <td>3.966226</td>\n      <td>24.816416</td>\n      <td>24.458256</td>\n      <td>43.193783</td>\n      <td>0.436114</td>\n      <td>43.095985</td>\n      <td>0.414003</td>\n      <td>61672.214844</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>-384.522156</td>\n      <td>45.525143</td>\n      <td>-75.231346</td>\n      <td>1.285414</td>\n      <td>-1.103038</td>\n      <td>12.836702</td>\n      <td>35.268780</td>\n      <td>37.536816</td>\n      <td>0.839387</td>\n      <td>40.914211</td>\n      <td>0.545149</td>\n      <td>206372.734375</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_inverse=scaler.inverse_transform(fake)\n",
    "fake_tasks_df=pd.DataFrame(fake_inverse,columns=df.columns[:-1])\n",
    "fake_tasks_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "fake_tasks_df.to_csv('Generated_fake_milicious_tasks.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the goodness of our generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "1    1862\n0     138\ndtype: int64"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = adaBoostClassifier.predict(fake_tasks_df)\n",
    "pd.DataFrame(mm).value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here the model is wrong in 1862 sample and right in only 138 sample and this is a good evidence that we succeeded in scammimg the model because all this tasks should be calssified as unligitmate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Mix the generated fake tasks with the original test dataset to obtain a new test dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mixing step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "data": {
      "text/plain": "               ID   Latitude  Longitude       Day       Hour     Minute  \\\n0     1031.000000  45.556369 -75.201917  3.000000  11.000000   9.000000   \n1      209.000000  45.469987 -75.155623  4.000000  16.000000   8.000000   \n2     3653.000000  45.536579 -75.161880  5.000000   8.000000  35.000000   \n3       94.000000  45.392164 -75.235236  4.000000   4.000000  36.000000   \n4     1283.000000  45.496407 -75.183561  4.000000   4.000000   1.000000   \n...           ...        ...        ...       ...        ...        ...   \n4892  -444.878815  45.526932 -75.300354  0.836905  -1.133905  15.083454   \n4893  -273.710052  45.553280 -75.239441  2.016987   0.202000   6.865791   \n4894  -143.908173  45.538853 -75.241570  1.251927  -0.380992   1.363171   \n4895  -452.967377  45.521236 -75.309387  1.625790   3.966226  24.816416   \n4896  -384.522156  45.525143 -75.231346  1.285414  -1.103038  12.836702   \n\n       Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n0     40.000000      20.000000   1.000000  86.000000     0.000000   \n1     60.000000      10.000000   8.000000  53.000000     0.000000   \n2     50.000000      30.000000   8.000000  63.000000     1.000000   \n3     40.000000      30.000000   6.000000  74.000000     0.000000   \n4     50.000000      30.000000   5.000000  60.000000     0.000000   \n...         ...            ...        ...        ...          ...   \n4892  17.918312      29.723480   0.382905  30.735096     0.497608   \n4893  23.347864      40.295158   0.284052  50.410530     0.466032   \n4894  17.889383      45.678703  -0.430957  28.103292     0.531100   \n4895  24.458256      43.193783   0.436114  43.095985     0.414003   \n4896  35.268780      37.536816   0.839387  40.914211     0.545149   \n\n         GridNumber  \n0     319073.000000  \n1     178319.000000  \n2     290926.000000  \n3      37549.000000  \n4     215851.000000  \n...             ...  \n4892  242898.890625  \n4893  204299.546875  \n4894  -23143.039062  \n4895   61672.214844  \n4896  206372.734375  \n\n[4897 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1031.000000</td>\n      <td>45.556369</td>\n      <td>-75.201917</td>\n      <td>3.000000</td>\n      <td>11.000000</td>\n      <td>9.000000</td>\n      <td>40.000000</td>\n      <td>20.000000</td>\n      <td>1.000000</td>\n      <td>86.000000</td>\n      <td>0.000000</td>\n      <td>319073.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>209.000000</td>\n      <td>45.469987</td>\n      <td>-75.155623</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n      <td>8.000000</td>\n      <td>60.000000</td>\n      <td>10.000000</td>\n      <td>8.000000</td>\n      <td>53.000000</td>\n      <td>0.000000</td>\n      <td>178319.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3653.000000</td>\n      <td>45.536579</td>\n      <td>-75.161880</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>35.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>8.000000</td>\n      <td>63.000000</td>\n      <td>1.000000</td>\n      <td>290926.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>94.000000</td>\n      <td>45.392164</td>\n      <td>-75.235236</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>36.000000</td>\n      <td>40.000000</td>\n      <td>30.000000</td>\n      <td>6.000000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>37549.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1283.000000</td>\n      <td>45.496407</td>\n      <td>-75.183561</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>5.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>215851.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4892</th>\n      <td>-444.878815</td>\n      <td>45.526932</td>\n      <td>-75.300354</td>\n      <td>0.836905</td>\n      <td>-1.133905</td>\n      <td>15.083454</td>\n      <td>17.918312</td>\n      <td>29.723480</td>\n      <td>0.382905</td>\n      <td>30.735096</td>\n      <td>0.497608</td>\n      <td>242898.890625</td>\n    </tr>\n    <tr>\n      <th>4893</th>\n      <td>-273.710052</td>\n      <td>45.553280</td>\n      <td>-75.239441</td>\n      <td>2.016987</td>\n      <td>0.202000</td>\n      <td>6.865791</td>\n      <td>23.347864</td>\n      <td>40.295158</td>\n      <td>0.284052</td>\n      <td>50.410530</td>\n      <td>0.466032</td>\n      <td>204299.546875</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>-143.908173</td>\n      <td>45.538853</td>\n      <td>-75.241570</td>\n      <td>1.251927</td>\n      <td>-0.380992</td>\n      <td>1.363171</td>\n      <td>17.889383</td>\n      <td>45.678703</td>\n      <td>-0.430957</td>\n      <td>28.103292</td>\n      <td>0.531100</td>\n      <td>-23143.039062</td>\n    </tr>\n    <tr>\n      <th>4895</th>\n      <td>-452.967377</td>\n      <td>45.521236</td>\n      <td>-75.309387</td>\n      <td>1.625790</td>\n      <td>3.966226</td>\n      <td>24.816416</td>\n      <td>24.458256</td>\n      <td>43.193783</td>\n      <td>0.436114</td>\n      <td>43.095985</td>\n      <td>0.414003</td>\n      <td>61672.214844</td>\n    </tr>\n    <tr>\n      <th>4896</th>\n      <td>-384.522156</td>\n      <td>45.525143</td>\n      <td>-75.231346</td>\n      <td>1.285414</td>\n      <td>-1.103038</td>\n      <td>12.836702</td>\n      <td>35.268780</td>\n      <td>37.536816</td>\n      <td>0.839387</td>\n      <td>40.914211</td>\n      <td>0.545149</td>\n      <td>206372.734375</td>\n    </tr>\n  </tbody>\n</table>\n<p>4897 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_test_dataset=pd.concat([X_test,fake_tasks_df])\n",
    "mixed_test_dataset=mixed_test_dataset.reset_index()\n",
    "mixed_test_dataset.drop('index',axis=1,inplace=True)\n",
    "mixed_test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We should label all these tasks as unligitimate tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "data": {
      "text/plain": "      Ligitimacy\n0              1\n1              0\n2              0\n3              1\n4              1\n...          ...\n4892           0\n4893           0\n4894           0\n4895           0\n4896           0\n\n[4897 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ligitimacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4892</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4893</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4895</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4896</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4897 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_fake_tasks=pd.DataFrame({'Ligitimacy':[0]*2000},)\n",
    "mixed_y_test=pd.concat([y_test,y_for_fake_tasks['Ligitimacy']])\n",
    "mixed_y_test=mixed_y_test.reset_index()\n",
    "mixed_y_test.drop('index',axis=1,inplace=True)\n",
    "mixed_y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obtain Adaboost and RF detection performance using the new test dataset and present results in bar chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier accuracy for the mixed data= 0.5758627731264039\n",
      "RandomForestClassifier accuracy for the mixed data = 0.5909740657545436\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaboost_accuracy=adaBoostClassifier.score(mixed_test_dataset,mixed_y_test)\n",
    "rf_accuracy=randomForestClassifier.score(mixed_test_dataset,mixed_y_test)\n",
    "print(f'AdaBoostClassifier accuracy for the mixed data= {adaboost_accuracy}')\n",
    "print(f'RandomForestClassifier accuracy for the mixed data = {rf_accuracy}')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylim(0,1)\n",
    "sns.barplot(x=['AdaBoost','RandomForest'],y=[adaboost_accuracy,rf_accuracy],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We can notice that in Adaboost the accuracy has been decreased from 0.925 to 0.575 .\n",
    "### and in Random forest the accuracy has been decreased from 0.990 to 0.590.\n",
    "## So, our generation is good and scammed the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Consider the Discriminator to as the first level classifier and RF/Adaboost as the second level classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Because of our discriminator is trained on scaled data, so we will scale this data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.25756439,  0.87078121,  0.53914657, ...,  0.8       ,\n         0.        ,  0.85363261],\n       [ 0.052013  ,  0.4764824 ,  0.72794642, ...,  0.32857143,\n         0.        ,  0.4878012 ],\n       [ 0.91322831,  0.78044984,  0.70242734, ...,  0.47142857,\n         1.        ,  0.7804762 ],\n       ...,\n       [-0.0362361 ,  0.79082618,  0.37743027, ..., -0.02709582,\n         0.53109992, -0.03581547],\n       [-0.11352022,  0.71041532,  0.10085008, ...,  0.18708551,\n         0.41400257,  0.18462646],\n       [-0.09640464,  0.72824571,  0.41912421, ...,  0.1559173 ,\n         0.54514861,  0.5607152 ]])"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_test_dataset_scaled=scaler.transform(mixed_test_dataset)\n",
    "mixed_test_dataset_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concat the labels as one hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4897, 14])"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_examples_for_mixed_dataset = keras.utils.to_categorical(mixed_y_test, 2)\n",
    "mixed_test_dataset_scaled_and_labels = tf.concat([mixed_test_dataset_scaled, one_hot_examples_for_mixed_dataset], 1)\n",
    "mixed_test_dataset_scaled_and_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detect the real and fake tasks using the discriminator as first level classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "trained_disc=cgan.discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "      0\n0     1\n1     1\n2     1\n3     1\n4     1\n...  ..\n4892  0\n4893  0\n4894  0\n4895  0\n4896  0\n\n[4897 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4892</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4893</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4895</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4896</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4897 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mixed_from_disc=trained_disc.predict(mixed_test_dataset_scaled_and_labels)\n",
    "y_pred_mixed_from_disc=np.apply_along_axis(lambda x:1 if x >=0.5 else 0,axis=1,arr=y_pred_mixed_from_disc,)\n",
    "y_pred_mixed_from_disc=pd.DataFrame(y_pred_mixed_from_disc)\n",
    "y_pred_mixed_from_disc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter synthetic tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "data": {
      "text/plain": "               ID   Latitude  Longitude       Day       Hour     Minute  \\\n0     1031.000000  45.556369 -75.201917  3.000000  11.000000   9.000000   \n1      209.000000  45.469987 -75.155623  4.000000  16.000000   8.000000   \n2     3653.000000  45.536579 -75.161880  5.000000   8.000000  35.000000   \n3       94.000000  45.392164 -75.235236  4.000000   4.000000  36.000000   \n4     1283.000000  45.496407 -75.183561  4.000000   4.000000   1.000000   \n...           ...        ...        ...       ...        ...        ...   \n2894  3426.000000  45.504521 -75.275448  5.000000  23.000000  56.000000   \n2895  3085.000000  45.551647 -75.291245  0.000000  22.000000  47.000000   \n2896  3944.000000  45.481815 -75.122325  4.000000   7.000000  23.000000   \n2978  -800.467224  45.450020 -75.255432  2.875970  15.527442  30.839828   \n3165  -694.330139  45.471256 -75.226410  2.639071  14.563126  26.370493   \n\n       Duration  RemainingTime  Resources   Coverage  OnPeakHours  \\\n0     40.000000      20.000000   1.000000  86.000000     0.000000   \n1     60.000000      10.000000   8.000000  53.000000     0.000000   \n2     50.000000      30.000000   8.000000  63.000000     1.000000   \n3     40.000000      30.000000   6.000000  74.000000     0.000000   \n4     50.000000      30.000000   5.000000  60.000000     0.000000   \n...         ...            ...        ...        ...          ...   \n2894  40.000000      10.000000   4.000000  38.000000     0.000000   \n2895  40.000000      30.000000   2.000000  33.000000     0.000000   \n2896  20.000000      10.000000   4.000000  96.000000     1.000000   \n2978  82.083557      31.887712  11.261337  75.919724     0.270175   \n3165  69.529030      22.593563   8.230106  27.741718     0.185040   \n\n        GridNumber  \n0     319073.00000  \n1     178319.00000  \n2     290926.00000  \n3      37549.00000  \n4     215851.00000  \n...            ...  \n2894  234608.00000  \n2895  319062.00000  \n2896  197091.00000  \n2978  788574.43750  \n3165  435225.59375  \n\n[2881 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Day</th>\n      <th>Hour</th>\n      <th>Minute</th>\n      <th>Duration</th>\n      <th>RemainingTime</th>\n      <th>Resources</th>\n      <th>Coverage</th>\n      <th>OnPeakHours</th>\n      <th>GridNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1031.000000</td>\n      <td>45.556369</td>\n      <td>-75.201917</td>\n      <td>3.000000</td>\n      <td>11.000000</td>\n      <td>9.000000</td>\n      <td>40.000000</td>\n      <td>20.000000</td>\n      <td>1.000000</td>\n      <td>86.000000</td>\n      <td>0.000000</td>\n      <td>319073.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>209.000000</td>\n      <td>45.469987</td>\n      <td>-75.155623</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n      <td>8.000000</td>\n      <td>60.000000</td>\n      <td>10.000000</td>\n      <td>8.000000</td>\n      <td>53.000000</td>\n      <td>0.000000</td>\n      <td>178319.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3653.000000</td>\n      <td>45.536579</td>\n      <td>-75.161880</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>35.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>8.000000</td>\n      <td>63.000000</td>\n      <td>1.000000</td>\n      <td>290926.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>94.000000</td>\n      <td>45.392164</td>\n      <td>-75.235236</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>36.000000</td>\n      <td>40.000000</td>\n      <td>30.000000</td>\n      <td>6.000000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>37549.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1283.000000</td>\n      <td>45.496407</td>\n      <td>-75.183561</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>50.000000</td>\n      <td>30.000000</td>\n      <td>5.000000</td>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>215851.00000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2894</th>\n      <td>3426.000000</td>\n      <td>45.504521</td>\n      <td>-75.275448</td>\n      <td>5.000000</td>\n      <td>23.000000</td>\n      <td>56.000000</td>\n      <td>40.000000</td>\n      <td>10.000000</td>\n      <td>4.000000</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>234608.00000</td>\n    </tr>\n    <tr>\n      <th>2895</th>\n      <td>3085.000000</td>\n      <td>45.551647</td>\n      <td>-75.291245</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>47.000000</td>\n      <td>40.000000</td>\n      <td>30.000000</td>\n      <td>2.000000</td>\n      <td>33.000000</td>\n      <td>0.000000</td>\n      <td>319062.00000</td>\n    </tr>\n    <tr>\n      <th>2896</th>\n      <td>3944.000000</td>\n      <td>45.481815</td>\n      <td>-75.122325</td>\n      <td>4.000000</td>\n      <td>7.000000</td>\n      <td>23.000000</td>\n      <td>20.000000</td>\n      <td>10.000000</td>\n      <td>4.000000</td>\n      <td>96.000000</td>\n      <td>1.000000</td>\n      <td>197091.00000</td>\n    </tr>\n    <tr>\n      <th>2978</th>\n      <td>-800.467224</td>\n      <td>45.450020</td>\n      <td>-75.255432</td>\n      <td>2.875970</td>\n      <td>15.527442</td>\n      <td>30.839828</td>\n      <td>82.083557</td>\n      <td>31.887712</td>\n      <td>11.261337</td>\n      <td>75.919724</td>\n      <td>0.270175</td>\n      <td>788574.43750</td>\n    </tr>\n    <tr>\n      <th>3165</th>\n      <td>-694.330139</td>\n      <td>45.471256</td>\n      <td>-75.226410</td>\n      <td>2.639071</td>\n      <td>14.563126</td>\n      <td>26.370493</td>\n      <td>69.529030</td>\n      <td>22.593563</td>\n      <td>8.230106</td>\n      <td>27.741718</td>\n      <td>0.185040</td>\n      <td>435225.59375</td>\n    </tr>\n  </tbody>\n</table>\n<p>2881 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_of_real=y_pred_mixed_from_disc[y_pred_mixed_from_disc[0]==1].index.tolist()\n",
    "filtered_real_tasks=mixed_test_dataset.loc[index_of_real,:]\n",
    "filtered_real_tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "      Ligitimacy\n0              1\n1              0\n2              0\n3              1\n4              1\n...          ...\n2894           1\n2895           1\n2896           1\n2978           0\n3165           0\n\n[2881 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ligitimacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2894</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2895</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2896</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2978</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3165</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2881 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual_of_filtered_tasks=mixed_y_test.loc[index_of_real,:]\n",
    "y_actual_of_filtered_tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the classic classifiers as a second level after filtering the fake tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier accuracy for the mixed data= 0.9260673377299549\n",
      "RandomForestClassifier accuracy for the mixed data = 0.9930579659840333\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_ada_for_filtered_mixed_test=adaBoostClassifier.predict(filtered_real_tasks)\n",
    "y_pred_rf_for_filtered_mixed_test=randomForestClassifier.predict(filtered_real_tasks)\n",
    "adaboost_accuracy=accuracy_score(y_actual_of_filtered_tasks,y_pred_ada_for_filtered_mixed_test)\n",
    "rf_accuracy=accuracy_score(y_actual_of_filtered_tasks,y_pred_rf_for_filtered_mixed_test)\n",
    "print(f'AdaBoostClassifier accuracy for the mixed data= {adaboost_accuracy}')\n",
    "print(f'RandomForestClassifier accuracy for the mixed data = {rf_accuracy}')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylim(0,1)\n",
    "sns.barplot(x=['AdaBoost','RandomForest'],y=[adaboost_accuracy,rf_accuracy],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This is approximately the original accuracies before adding the fake tasks, and it's a good results because our discriminator is able to filter the fake tasks and our classic classifiers are now able to classify the real tasks if they ligitimit or not as they used to do"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wgan_gp",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}